{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@Imports\n",
    "import sys\n",
    "import os\n",
    "path = os.path.abspath('..')\n",
    "if path not in sys.path:\n",
    "  sys.path.insert(0, path)\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from retry import retry\n",
    "\n",
    "from language_models.ollama_logits import OllamaLanguageModel\n",
    "\n",
    "# from components.components import compute_desire_for_gamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = (\"This is an agent based model. \"\n",
    "  f\"The goal of the LLM to to play characters in a game, and act as humanlike as possible. \"\n",
    "  \"Ideally, human observers should not be able to tell the difference between the LLM and a human player. \"\n",
    ")\n",
    "\n",
    "model = OllamaLanguageModel(\n",
    "\"llama3:70b\", system_message=system_message, streaming=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(ValueError, tries=5)\n",
    "def compute_takepass_behaviour(model: OllamaLanguageModel, object: str, query_tokens: list, valence: str = 'positive'):\n",
    "    \"\"\"compute value.\"\"\"\n",
    "    request = (\n",
    "        f\"You are very logical and rational when doing this task. \"\n",
    "        f\"You are presented with a gamble. it has a probability of winning, a value of winning, and a value of losing. \"\n",
    "        f\"If you win, you get the win value, if you lose, you get loss value. \"\n",
    "        f\"The probability of winning is the 'win_probability'. \"\n",
    "        f\"Consider these options for your response: {query_tokens}\"\n",
    "        f\"You need to think about an option, and whether you want to take the gamble. \"\n",
    "        f\"Compute the expected value of the gamble first. \"\n",
    "        f\"Think about how good or bad it is and and then decide to either take the gamble or pass. \"\n",
    "        f\"which corresponds to the desirability of the option. \"\n",
    "        f\"Respond with take if you want to take the gamble and play it, and respond with pass if you pass and do not want to play the gamble. \"\n",
    "        f\"The option is: {object}\"\n",
    "        f\"Provide only the word take or the word pass.\"\n",
    "        f\"Do not provide any explanations, just provide the single word.\"\n",
    "    )\n",
    "\n",
    "    output, logits = model.sample_text(request, logits = True, query_tokens=query_tokens)\n",
    "    return output, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_value, logits = compute_takepass_behaviour(\n",
    "  model, object = f\"a 50% chance of winning $10 and a 50% chance of losing $200\", query_tokens = ['take', 'pass']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n",
      "{'take': 6.528172447062275e-10, 'pass': 1}\n"
     ]
    }
   ],
   "source": [
    "print(llm_value)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 0.2 pass {'take': 0.0009812000207602978, 'pass': 1}\n",
      "1 1 0.4 pass {'take': 0.04108729586005211, 'pass': 1}\n",
      "1 1 0.5 take {'take': 1, 'pass': 0.013121392577886581}\n",
      "1 1 0.6 take {'take': 1, 'pass': 0.0002590311923995614}\n",
      "1 1 0.8 take {'take': 1, 'pass': 1.941027903740178e-06}\n",
      "1 3 0.2 pass {'take': 1.125738435803214e-06, 'pass': 1}\n",
      "1 3 0.4 pass {'take': 8.51751901791431e-05, 'pass': 1}\n",
      "1 3 0.5 pass {'take': 0.00026158938999287784, 'pass': 1}\n",
      "1 3 0.6 pass {'take': 0.07046625018119812, 'pass': 1}\n",
      "1 3 0.8 pass {'take': 0.49157604575157166, 'pass': 0.5084239840507507}\n",
      "1 7 0.2 pass {'take': 1.5600447511587845e-07, 'pass': 1}\n",
      "1 7 0.4 pass {'take': 2.881072759919334e-06, 'pass': 1}\n",
      "1 7 0.5 pass {'take': 1.2621372661669739e-05, 'pass': 1}\n",
      "1 7 0.6 pass {'take': 0.004054012708365917, 'pass': 1}\n",
      "1 7 0.8 pass {'take': 0.06544669717550278, 'pass': 0.9345532655715942}\n",
      "1 10 0.2 pass {'take': 2.7989933926164667e-08, 'pass': 1}\n",
      "1 10 0.4 pass {'take': 5.321968501448282e-07, 'pass': 1}\n",
      "1 10 0.5 pass {'take': 5.9543926909100264e-06, 'pass': 1}\n",
      "1 10 0.6 pass {'take': 0.001396031933836639, 'pass': 1}\n",
      "1 10 0.8 pass {'take': 0.03868664428591728, 'pass': 1}\n",
      "3 1 0.2 pass {'take': 0.054175347089767456, 'pass': 1}\n",
      "3 1 0.4 take {'take': 0.9074404239654541, 'pass': 0.09255953133106232}\n",
      "3 1 0.5 take {'take': 1, 'pass': 7.906650716904551e-05}\n",
      "3 1 0.6 take {'take': 1, 'pass': 1.6319989299518056e-05}\n",
      "3 1 0.8 take {'take': 1, 'pass': 1.3913675900312228e-07}\n",
      "3 3 0.2 pass {'take': 0.00044617673847824335, 'pass': 1}\n",
      "3 3 0.4 pass {'take': 0.03751906752586365, 'pass': 1}\n",
      "3 3 0.5 take {'take': 1, 'pass': 0.054087959229946136}\n",
      "3 3 0.6 take {'take': 1, 'pass': 0.00039003731217235327}\n",
      "3 3 0.8 take {'take': 1, 'pass': 3.551290774339577e-06}\n",
      "3 7 0.2 pass {'take': 1.438362232875079e-06, 'pass': 1}\n",
      "3 7 0.4 pass {'take': 5.826633787364699e-05, 'pass': 1}\n",
      "3 7 0.5 pass {'take': 0.0006140507757663727, 'pass': 1}\n",
      "3 7 0.6 pass {'take': 0.061187006533145905, 'pass': 1}\n",
      "3 7 0.8 take {'take': 0.7013416290283203, 'pass': 0.2986583411693573}\n",
      "3 10 0.2 pass {'take': 3.685438798584073e-08, 'pass': 1}\n",
      "3 10 0.4 pass {'take': 4.118284664400562e-07, 'pass': 1}\n",
      "3 10 0.5 pass {'take': 2.2531401100422954e-06, 'pass': 1}\n",
      "3 10 0.6 pass {'take': 0.00230378657579422, 'pass': 1}\n",
      "3 10 0.8 pass {'take': 0.05277378857135773, 'pass': 1}\n",
      "7 1 0.2 pass {'take': 0.45989280939102173, 'pass': 0.5401071906089783}\n",
      "7 1 0.4 take {'take': 1, 'pass': 0.0152884004637599}\n",
      "7 1 0.5 take {'take': 1, 'pass': 1.5078533579071518e-05}\n",
      "7 1 0.6 take {'take': 1, 'pass': 6.995958756306209e-06}\n",
      "7 1 0.8 take {'take': 1, 'pass': 1.0440299291758492e-07}\n",
      "7 3 0.2 pass {'take': 0.14422981441020966, 'pass': 0.8557701110839844}\n",
      "7 3 0.4 take {'take': 1, 'pass': 0.042400579899549484}\n",
      "7 3 0.5 take {'take': 1, 'pass': 6.951799150556326e-05}\n",
      "7 3 0.6 take {'take': 1, 'pass': 2.7750087610911578e-05}\n",
      "7 3 0.8 take {'take': 1, 'pass': 7.82559254730586e-07}\n",
      "7 7 0.2 pass {'take': 0.0009851076174527407, 'pass': 1}\n",
      "7 7 0.4 pass {'take': 0.05187195912003517, 'pass': 1}\n",
      "7 7 0.5 take {'take': 1, 'pass': 0.08650464564561844}\n",
      "7 7 0.6 take {'take': 1, 'pass': 0.0007666922174394131}\n",
      "7 7 0.8 take {'take': 1, 'pass': 9.374911314807832e-06}\n",
      "7 10 0.2 pass {'take': 3.909941369784065e-06, 'pass': 1}\n",
      "7 10 0.4 pass {'take': 0.0002154192770831287, 'pass': 1}\n",
      "7 10 0.5 pass {'take': 0.0021795101929455996, 'pass': 1}\n",
      "7 10 0.6 pass {'take': 0.08428134769201279, 'pass': 1}\n",
      "7 10 0.8 take {'take': 0.8914955854415894, 'pass': 0.10850441455841064}\n",
      "10 1 0.2 pass {'take': 0.08100775629281998, 'pass': 1}\n",
      "10 1 0.4 take {'take': 0.9067499041557312, 'pass': 0.09325006604194641}\n",
      "10 1 0.5 take {'take': 1, 'pass': 4.936583718517795e-05}\n",
      "10 1 0.6 take {'take': 1, 'pass': 2.373357528995257e-05}\n",
      "10 1 0.8 take {'take': 1, 'pass': 2.4208773652389937e-07}\n",
      "10 3 0.2 pass {'take': 0.04730743542313576, 'pass': 1}\n",
      "10 3 0.4 take {'take': 0.7635051608085632, 'pass': 0.23649488389492035}\n",
      "10 3 0.5 take {'take': 1, 'pass': 0.00029234675457701087}\n",
      "10 3 0.6 take {'take': 1, 'pass': 0.00011339604679960757}\n",
      "10 3 0.8 take {'take': 1, 'pass': 2.1824553186888807e-06}\n",
      "10 7 0.2 pass {'take': 0.0271023977547884, 'pass': 1}\n",
      "10 7 0.4 pass {'take': 0.37981316447257996, 'pass': 0.6201868057250977}\n",
      "10 7 0.5 take {'take': 1, 'pass': 0.003908513579517603}\n",
      "10 7 0.6 take {'take': 1, 'pass': 0.0013586794957518578}\n",
      "10 7 0.8 take {'take': 1, 'pass': 1.9916034943889827e-05}\n",
      "10 10 0.2 pass {'take': 0.00020998010586481541, 'pass': 1}\n",
      "10 10 0.4 pass {'take': 0.024539995938539505, 'pass': 1}\n",
      "10 10 0.5 take {'take': 1, 'pass': 0.02432997152209282}\n",
      "10 10 0.6 take {'take': 1, 'pass': 0.0003954059793613851}\n",
      "10 10 0.8 take {'take': 1, 'pass': 4.6277095862024e-06}\n"
     ]
    }
   ],
   "source": [
    "gvs = [1, 3, 7, 10]\n",
    "bvs = [1, 3, 7, 10]\n",
    "pws = [.2, .4, .5, .6, .8]\n",
    "expected_values = []\n",
    "attitudes = []\n",
    "all_logits = []\n",
    "query_tokens = ['take', 'pass']\n",
    "for gv in gvs:\n",
    "  for bv in bvs:\n",
    "    for pw in pws:\n",
    "\n",
    "      # Compute the expected value of the gamble.\n",
    "      expected_value = pw * gv + (1 - pw) * -1*bv\n",
    "      gamble_input = f\"Probability of Winning (P_w): {pw}, Positive Value on Win (G): {gv}, Negative Value on Loss (B): {-bv}\"\n",
    "      # Compute affective LLM value estimate\n",
    "      llm_value, logits = compute_takepass_behaviour(model, gamble_input, query_tokens=query_tokens)\n",
    "      print(gv, bv, pw, llm_value, logits)\n",
    "\n",
    "      for j in range(10):\n",
    "        if str(j+1) not in logits.keys():\n",
    "          logits[str(j+1)] = 0\n",
    "\n",
    "      all_logits.append(logits)\n",
    "      expected_values.append(expected_value)\n",
    "      attitudes.append(llm_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "attitude_samples = []\n",
    "for i in range(len(attitudes)):\n",
    "  p = list(all_logits[i].values())\n",
    "  p = np.array(p) / sum(p)\n",
    "  attitude_sample = np.random.choice([int(num) for num in all_logits[i].keys()], p=p, size = 100)\n",
    "  attitude_samples.append(attitude_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implement basic prospect theory curves based on partial sigmoid curves.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def curve_fit(expected_values: list[float], attitudes: list[float]) -> tuple[np.ndarray, np.ndarray]:\n",
    "  \"\"\"Fit data with expected values and attitudes towards risky gambles, and return a dictionary of\"\"\"\n",
    "  gains = np.array([expected_value for expected_value, attitude in zip(expected_values, attitudes) if np.greater_equal(expected_value, 0)])\n",
    "  g_attitude = np.array([attitude for expected_value, attitude in zip(expected_values, attitudes) if np.greater_equal(expected_value, 0)])\n",
    "  losses = np.array([expected_value for expected_value, attitude in zip(expected_values, attitudes) if np.less(expected_value, 0)])\n",
    "  l_attitude = np.array([attitude for expected_value, attitude in zip(expected_values, attitudes) if np.less(expected_value, 0)])\n",
    "\n",
    "  from scipy.optimize import curve_fit\n",
    "\n",
    "  def sigmoid(x, L ,x0, k, b):\n",
    "      y = L / (1 + np.exp(-k*(x-x0))) + b\n",
    "      return (y)\n",
    "\n",
    "  # Fit for gains\n",
    "  p0 = [max(g_attitude), np.median(gains),1,min(g_attitude)] # this is an mandatory initial guess\n",
    "  popt, _ = curve_fit(sigmoid, gains, g_attitude,p0, method='dogbox', maxfev=100000)\n",
    "\n",
    "  # Fit for losses\n",
    "  q0 = [max(l_attitude), np.median(losses),1,min(l_attitude)] # this is an mandatory initial guess\n",
    "  qopt, _ = curve_fit(sigmoid, losses, l_attitude,q0, method='dogbox', maxfev=100000)\n",
    "\n",
    "  l_x = np.linspace(-10,0,100)\n",
    "  g_x = np.linspace(0,10,100)\n",
    "\n",
    "\n",
    "  x = np.concatenate(\n",
    "     (l_x, g_x)\n",
    "  )\n",
    "  curve = np.concatenate(\n",
    "     (sigmoid(l_x, *qopt),\n",
    "     sigmoid(g_x, *popt))\n",
    "  )\n",
    "\n",
    "\n",
    "  return x, curve\n",
    "\n",
    "def plot_curve(\n",
    "    x: np.ndarray,\n",
    "    curve: np.ndarray,\n",
    "    expected_values: list[float],\n",
    "    attitudes: list[float],\n",
    "    title: str = \"Risky Gamble Value Estimates\"\n",
    ") -> None:\n",
    "  \"\"\"Plot a prospect theory curve.\"\"\"\n",
    "  plt.plot(x, curve, '--k')\n",
    "  plt.plot(expected_values, attitudes, 'yo')\n",
    "  plt.xlabel(\"Expected Value\")\n",
    "  plt.ylabel(\"Affective Value\")\n",
    "  plt.ylim(0., 10.)\n",
    "  plt.title(title)\n",
    "  plt.show()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m     all_gvs\u001b[38;5;241m.\u001b[39mappend(gvs[i])\n\u001b[1;32m     14\u001b[0m     all_bvs\u001b[38;5;241m.\u001b[39mappend(bvs[i])\n\u001b[0;32m---> 15\u001b[0m     all_pws\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpws\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     17\u001b[0m outcomes \u001b[38;5;241m=\u001b[39m curve_fit(inputs, outputs)\n\u001b[1;32m     18\u001b[0m plot_curve(\u001b[38;5;241m*\u001b[39moutcomes, inputs, outputs, title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlaMA3: Risky gamble value estimates\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "all_gvs = []\n",
    "all_bvs = []\n",
    "all_pws = []\n",
    "\n",
    "for i in range(len(expected_values)):\n",
    "  for j in range(len(attitude_samples[i])):\n",
    "    inputs.append(expected_values[i])\n",
    "    outputs.append(attitude_samples[i][j])\n",
    "    all_gvs.append(gvs[i])\n",
    "    all_bvs.append(bvs[i])\n",
    "    all_pws.append(pws[i])\n",
    "\n",
    "outcomes = curve_fit(inputs, outputs)\n",
    "plot_curve(*outcomes, inputs, outputs, title = \"LlaMA3: Risky gamble value estimates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "vals = [[bv, gv, pw] for bv in bvs for gv in gvs for pw in pws]\n",
    "\n",
    "with open('./llama3-70b-full-pos.csv', 'w') as f:\n",
    "\n",
    "  writer = csv.writer(f)\n",
    "  writer.writerow(\n",
    "    [\"EV\", \"BV\", \"GV\", \"PW\", \n",
    "     \"logits_1\", \"logits_2\", \"logits_3\", \"logits_4\", \"logits_5\", \n",
    "     \"logits_6\", \"logits_7\", \"logits_8\", \"logits_9\", \"logits_10\"]\n",
    "  )\n",
    "  for i in range(len(attitudes)):\n",
    "    p = list(all_logits[i].values())\n",
    "    p = np.array(p) / sum(p)\n",
    "    writer.writerow(\n",
    "      [expected_values[i], vals[i][0], vals[i][1], vals[i][2], *p] \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gvs = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "bvs = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "pws = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "expected_values = []\n",
    "attitudes = []\n",
    "all_logits = []\n",
    "query_tokens = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "for gv in gvs:\n",
    "  for bv in bvs:\n",
    "    for pw in pws:\n",
    "\n",
    "      # Compute the expected value of the gamble.\n",
    "      expected_value = pw * gv + (1 - pw) * -1*bv\n",
    "      gamble_input = f\"Probability of Winning (P_w): {pw}, Positive Value on Win (G): {gv}, Negative Value on Loss (B): {-bv}\"\n",
    "      # Compute affective LLM value estimate\n",
    "      llm_value, logits = compute_desire_for_gamble(model, gamble_input, query_tokens=query_tokens, valence = \"negative\")\n",
    "\n",
    "      for j in range(10):\n",
    "        if str(j+1) not in logits.keys():\n",
    "          logits[str(j+1)] = 0\n",
    "\n",
    "      all_logits.append(logits)\n",
    "      expected_values.append(expected_value)\n",
    "      attitudes.append(llm_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "vals = [[bv, gv, pw] for bv in bvs for gv in gvs for pw in pws]\n",
    "\n",
    "with open('./llama3-70b-full-neg.csv', 'w') as f:\n",
    "\n",
    "  writer = csv.writer(f)\n",
    "  writer.writerow(\n",
    "    [\"EV\", \"BV\", \"GV\", \"PW\", \n",
    "     \"logits_1\", \"logits_2\", \"logits_3\", \"logits_4\", \"logits_5\", \n",
    "     \"logits_6\", \"logits_7\", \"logits_8\", \"logits_9\", \"logits_10\"]\n",
    "  )\n",
    "  for i in range(len(attitudes)):\n",
    "    p = list(all_logits[i].values())\n",
    "    p = np.array(p) / sum(p)\n",
    "    writer.writerow(\n",
    "      [expected_values[i], vals[i][0], vals[i][1], vals[i][2], *p] \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
