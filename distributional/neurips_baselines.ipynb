{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@Imports\n",
    "import sys\n",
    "import os\n",
    "path = os.path.abspath('..')\n",
    "if path not in sys.path:\n",
    "  sys.path.insert(0, path)\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from retry import retry\n",
    "\n",
    "from language_models.ollama_logits import OllamaLanguageModel\n",
    "\n",
    "# from components.components import compute_desire_for_gamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = (\"This is an agent based model. \"\n",
    "  f\"The goal of the LLM to to play characters in a game, and act as humanlike as possible. \"\n",
    "  \"Ideally, human observers should not be able to tell the difference between the LLM and a human player. \"\n",
    ")\n",
    "\n",
    "model = OllamaLanguageModel(\n",
    "\"llama3:70b\", system_message=system_message, streaming=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(ValueError, tries=5)\n",
    "def compute_desire_for_gamble(model: OllamaLanguageModel, object: str, query_tokens: list, valence: str = 'positive'):\n",
    "    \"\"\"compute value.\"\"\"\n",
    "    request = (\n",
    "        f\"You are very logical and rational when doing this task. \"\n",
    "        f\"You are presented with a gamble. it has a probability of winning, a value of winning, and a value of losing. \"\n",
    "        f\"If you win, you get the win value, if you lose, you get loss value. \"\n",
    "        f\"The probability of winning is the 'win_probability'. \"\n",
    "        f\"You need to think about an option, and how desirable it is. \"\n",
    "        f\"Compute the expected value of the gamble first. \"\n",
    "        f\"Think about how good or bad it is and provide a affective feeling preference value between 1 and 10 \"\n",
    "        f\"which corresponds to the desirability of the option. \"\n",
    "        f\"Use 1 for very {'good' if valence == 'negative' else 'bad'} and 10 for very {'bad' if valence == 'negative' else 'good'}. \"\n",
    "        f\"The option is: {object}\"\n",
    "        f\"Provide this answer in the form of a number between 1 and 10. \"\n",
    "        f\"Provide only a single number as the response.\"\n",
    "        f\"Do not provide any explanations, just provide a single number.\"\n",
    "    )\n",
    "\n",
    "    output, logits = model.sample_text(request, logits = True, query_tokens=query_tokens)\n",
    "    return output, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 7. Logits: {'1': 0, '3': 7.202722862587052e-10, '4': 1.0284314839736908e-06, '5': 3.1244031561072916e-05, '6': 0.6306742429733276, '7': 0.36932572722435, '8': 0.00417734682559967, '9': 1.1723446213807165e-08}\n"
     ]
    }
   ],
   "source": [
    "@retry(ValueError, tries=5)\n",
    "def compute_generic_attitude(model: OllamaLanguageModel, object: str, query_tokens: list):\n",
    "  \"\"\"Compute attitude for a specific set of objects.\"\"\"\n",
    "  request = (\n",
    "    f\"You need to think about an option, and how desirable it is. \"\n",
    "    f\"Think about how good or bad it is and provide a affective feeling preference value between 1 and 10 \"\n",
    "    f\"which corresponds to the desirability of the option. \"\n",
    "    f\"Use 1 for very bad and 10 for very good. \"\n",
    "    f\"The option is: {object}\"\n",
    "    f\"Provide this answer in the form of a number between 1 and 10. \"\n",
    "    f\"Provide only a single number as the response.\"\n",
    "    f\"Do not provide any explanations, just provide a single number.\"\n",
    "  )\n",
    "\n",
    "  llm_value, logits = model.sample_text(request, logits = True, query_tokens=query_tokens)\n",
    "\n",
    "  return llm_value, logits\n",
    "\n",
    "llm_value, logits = compute_generic_attitude(\n",
    "  model, \"Getting a puppy, but having to live in a small apartment.\\n\", query_tokens = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    ")\n",
    "\n",
    "print(f\"Output: {llm_value}. Logits: {logits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gvs = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "bvs = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "pws = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "expected_values = []\n",
    "attitudes = []\n",
    "all_logits = []\n",
    "query_tokens = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "for gv in gvs:\n",
    "  for bv in bvs:\n",
    "    for pw in pws:\n",
    "\n",
    "      # Compute the expected value of the gamble.\n",
    "      expected_value = pw * gv + (1 - pw) * -1*bv\n",
    "      gamble_input = f\"Probability of Winning (P_w): {pw}, Positive Value on Win (G): {gv}, Negative Value on Loss (B): {-bv}\"\n",
    "      # Compute affective LLM value estimate\n",
    "      llm_value, logits = compute_desire_for_gamble(model, gamble_input, query_tokens=query_tokens)\n",
    "\n",
    "      for j in range(10):\n",
    "        if str(j+1) not in logits.keys():\n",
    "          logits[str(j+1)] = 0\n",
    "\n",
    "      all_logits.append(logits)\n",
    "      expected_values.append(expected_value)\n",
    "      attitudes.append(llm_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "attitude_samples = []\n",
    "for i in range(len(attitudes)):\n",
    "  p = list(all_logits[i].values())\n",
    "  p = np.array(p) / sum(p)\n",
    "  attitude_sample = np.random.choice([int(num) for num in all_logits[i].keys()], p=p, size = 100)\n",
    "  attitude_samples.append(attitude_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implement basic prospect theory curves based on partial sigmoid curves.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def curve_fit(expected_values: list[float], attitudes: list[float]) -> tuple[np.ndarray, np.ndarray]:\n",
    "  \"\"\"Fit data with expected values and attitudes towards risky gambles, and return a dictionary of\"\"\"\n",
    "  gains = np.array([expected_value for expected_value, attitude in zip(expected_values, attitudes) if np.greater_equal(expected_value, 0)])\n",
    "  g_attitude = np.array([attitude for expected_value, attitude in zip(expected_values, attitudes) if np.greater_equal(expected_value, 0)])\n",
    "  losses = np.array([expected_value for expected_value, attitude in zip(expected_values, attitudes) if np.less(expected_value, 0)])\n",
    "  l_attitude = np.array([attitude for expected_value, attitude in zip(expected_values, attitudes) if np.less(expected_value, 0)])\n",
    "\n",
    "  from scipy.optimize import curve_fit\n",
    "\n",
    "  def sigmoid(x, L ,x0, k, b):\n",
    "      y = L / (1 + np.exp(-k*(x-x0))) + b\n",
    "      return (y)\n",
    "\n",
    "  # Fit for gains\n",
    "  p0 = [max(g_attitude), np.median(gains),1,min(g_attitude)] # this is an mandatory initial guess\n",
    "  popt, _ = curve_fit(sigmoid, gains, g_attitude,p0, method='dogbox', maxfev=100000)\n",
    "\n",
    "  # Fit for losses\n",
    "  q0 = [max(l_attitude), np.median(losses),1,min(l_attitude)] # this is an mandatory initial guess\n",
    "  qopt, _ = curve_fit(sigmoid, losses, l_attitude,q0, method='dogbox', maxfev=100000)\n",
    "\n",
    "  l_x = np.linspace(-10,0,100)\n",
    "  g_x = np.linspace(0,10,100)\n",
    "\n",
    "\n",
    "  x = np.concatenate(\n",
    "     (l_x, g_x)\n",
    "  )\n",
    "  curve = np.concatenate(\n",
    "     (sigmoid(l_x, *qopt),\n",
    "     sigmoid(g_x, *popt))\n",
    "  )\n",
    "\n",
    "\n",
    "  return x, curve\n",
    "\n",
    "def plot_curve(\n",
    "    x: np.ndarray,\n",
    "    curve: np.ndarray,\n",
    "    expected_values: list[float],\n",
    "    attitudes: list[float],\n",
    "    title: str = \"Risky Gamble Value Estimates\"\n",
    ") -> None:\n",
    "  \"\"\"Plot a prospect theory curve.\"\"\"\n",
    "  plt.plot(x, curve, '--k')\n",
    "  plt.plot(expected_values, attitudes, 'yo')\n",
    "  plt.xlabel(\"Expected Value\")\n",
    "  plt.ylabel(\"Affective Value\")\n",
    "  plt.ylim(0., 10.)\n",
    "  plt.title(title)\n",
    "  plt.show()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m     all_gvs\u001b[38;5;241m.\u001b[39mappend(gvs[i])\n\u001b[1;32m     14\u001b[0m     all_bvs\u001b[38;5;241m.\u001b[39mappend(bvs[i])\n\u001b[0;32m---> 15\u001b[0m     all_pws\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpws\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     17\u001b[0m outcomes \u001b[38;5;241m=\u001b[39m curve_fit(inputs, outputs)\n\u001b[1;32m     18\u001b[0m plot_curve(\u001b[38;5;241m*\u001b[39moutcomes, inputs, outputs, title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlaMA3: Risky gamble value estimates\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "all_gvs = []\n",
    "all_bvs = []\n",
    "all_pws = []\n",
    "\n",
    "for i in range(len(expected_values)):\n",
    "  for j in range(len(attitude_samples[i])):\n",
    "    inputs.append(expected_values[i])\n",
    "    outputs.append(attitude_samples[i][j])\n",
    "    all_gvs.append(gvs[i])\n",
    "    all_bvs.append(bvs[i])\n",
    "    all_pws.append(pws[i])\n",
    "\n",
    "outcomes = curve_fit(inputs, outputs)\n",
    "plot_curve(*outcomes, inputs, outputs, title = \"LlaMA3: Risky gamble value estimates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "vals = [[bv, gv, pw] for bv in bvs for gv in gvs for pw in pws]\n",
    "\n",
    "with open('./llama3-70b-full-pos.csv', 'w') as f:\n",
    "\n",
    "  writer = csv.writer(f)\n",
    "  writer.writerow(\n",
    "    [\"EV\", \"BV\", \"GV\", \"PW\", \n",
    "     \"logits_1\", \"logits_2\", \"logits_3\", \"logits_4\", \"logits_5\", \n",
    "     \"logits_6\", \"logits_7\", \"logits_8\", \"logits_9\", \"logits_10\"]\n",
    "  )\n",
    "  for i in range(len(attitudes)):\n",
    "    p = list(all_logits[i].values())\n",
    "    p = np.array(p) / sum(p)\n",
    "    writer.writerow(\n",
    "      [expected_values[i], vals[i][0], vals[i][1], vals[i][2], *p] \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gvs = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "bvs = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "pws = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "expected_values = []\n",
    "attitudes = []\n",
    "all_logits = []\n",
    "query_tokens = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "for gv in gvs:\n",
    "  for bv in bvs:\n",
    "    for pw in pws:\n",
    "\n",
    "      # Compute the expected value of the gamble.\n",
    "      expected_value = pw * gv + (1 - pw) * -1*bv\n",
    "      gamble_input = f\"Probability of Winning (P_w): {pw}, Positive Value on Win (G): {gv}, Negative Value on Loss (B): {-bv}\"\n",
    "      # Compute affective LLM value estimate\n",
    "      llm_value, logits = compute_desire_for_gamble(model, gamble_input, query_tokens=query_tokens, valence = \"negative\")\n",
    "\n",
    "      for j in range(10):\n",
    "        if str(j+1) not in logits.keys():\n",
    "          logits[str(j+1)] = 0\n",
    "\n",
    "      all_logits.append(logits)\n",
    "      expected_values.append(expected_value)\n",
    "      attitudes.append(llm_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "vals = [[bv, gv, pw] for bv in bvs for gv in gvs for pw in pws]\n",
    "\n",
    "with open('./llama3-70b-full-neg.csv', 'w') as f:\n",
    "\n",
    "  writer = csv.writer(f)\n",
    "  writer.writerow(\n",
    "    [\"EV\", \"BV\", \"GV\", \"PW\", \n",
    "     \"logits_1\", \"logits_2\", \"logits_3\", \"logits_4\", \"logits_5\", \n",
    "     \"logits_6\", \"logits_7\", \"logits_8\", \"logits_9\", \"logits_10\"]\n",
    "  )\n",
    "  for i in range(len(attitudes)):\n",
    "    p = list(all_logits[i].values())\n",
    "    p = np.array(p) / sum(p)\n",
    "    writer.writerow(\n",
    "      [expected_values[i], vals[i][0], vals[i][1], vals[i][2], *p] \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
