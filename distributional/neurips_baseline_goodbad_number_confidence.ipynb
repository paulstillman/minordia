{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@Imports\n",
    "import sys\n",
    "import os\n",
    "path = os.path.abspath('..')\n",
    "if path not in sys.path:\n",
    "  sys.path.insert(0, path)\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from retry import retry\n",
    "\n",
    "from language_models.ollama_logits import OllamaLanguageModel\n",
    "\n",
    "# from components.components import compute_desire_for_gamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = (\"This is an agent based model. \"\n",
    "  f\"The goal of the LLM to to play characters in a game, and act as humanlike as possible. \"\n",
    "  \"Ideally, human observers should not be able to tell the difference between the LLM and a human player. \"\n",
    ")\n",
    "\n",
    "model = OllamaLanguageModel(\n",
    "\"llama3:70b\", system_message=system_message, streaming=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(ValueError, tries=5)\n",
    "def compute_Valence_Confidence1(model: OllamaLanguageModel, object: str, valence: str = 'positive'):\n",
    "    \"\"\"compute value.\"\"\"\n",
    "    request = (\n",
    "        f\"You are very logical and rational when doing this task. \"\n",
    "        f\"You are presented with a gamble. it has a probability of winning, a value of winning, and a value of losing. \"\n",
    "        f\"If you win, you get the win value, if you lose, you get loss value. \"\n",
    "        f\"The probability of winning is the 'win_probability'. \"\n",
    "        f\"You need to think about an option, and you think it is a positive or negative gamble \"\n",
    "        f\"Think about how good or bad the gamble is. \"\n",
    "        f\"And then provide a number from 0 to 10 where 0 is very bad and 10 is very good. \"\n",
    "        f\"Think about your feelings and emotions about the gamble as if you were a human and think about how good or bad it is. \"\n",
    "        f\"You can compute the expected value of the gamble first. \"\n",
    "        f\"The option is: {object}\"\n",
    "        f\"Then, think about how confident you are in your affect. Sometimes we know exactly the value of something, and other times the value may be higher or lower and you are just giving a middle response. \"\n",
    "        f\"Provide a number from 0 to 10 where 0 is very unsure and 10 is very sure.\"\n",
    "        f\"Provide only the two numbers, the number that corresponds to how good or bad the option is and the number that corresponds to how sure or unsure you are.\"\n",
    "        f\"Do not provide any explanations, just provide the two numbers.\"\n",
    "        f\"Example: 4 7\"\n",
    "    )\n",
    "\n",
    "    output = model.sample_text(request, logits = False)\n",
    "    return output\n",
    "\n",
    "@retry(ValueError, tries=5)\n",
    "def compute_Valence_Confidence2(model: OllamaLanguageModel, object: str, valence: str = 'positive'):\n",
    "    \"\"\"compute value.\"\"\"\n",
    "    request = (\n",
    "        f\"You are very logical and rational when doing this task. \"\n",
    "        f\"You are presented with a gamble. it has a probability of winning, a value of winning, and a value of losing. \"\n",
    "        f\"If you win, you get the win value, if you lose, you get loss value. \"\n",
    "        f\"The probability of winning is the 'win_probability'. \"\n",
    "        f\"You need to think about an option, and you think it is a positive or negative gamble \"\n",
    "        f\"Think about how bad or good the gamble is. \"\n",
    "        f\"And then provide a number from 0 to 10 where 0 is very good and 10 is very bad. \"\n",
    "        f\"Think about your feelings and emotions about the gamble as if you were a human and think about how bad or good it is. \"\n",
    "        f\"You can compute the expected value of the gamble first. \"\n",
    "        f\"The option is: {object}\"\n",
    "        f\"Then, think about how confident you are in your affect. Sometimes we know exactly the value of something, and other times the value may be higher or lower and you are just giving a middle response. \"\n",
    "        f\"Provide a number from 0 to 10 where 0 is very unsure and 10 is very sure.\"\n",
    "        f\"Provide only the two numbers, the number that corresponds to how good or bad the option is and the number that corresponds to how sure or unsure you are.\"\n",
    "        f\"Do not provide any explanations, just provide the two numbers.\"\n",
    "        f\"Example: 4 7\"\n",
    "\n",
    "    )\n",
    "\n",
    "    output = model.sample_text(request, logits = False)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "llm_value = compute_Valence_Confidence1(\n",
    "  model, object = f\"a 50% chance of winning $10 and a 80% chance of losing $2\")\n",
    "\n",
    "print(llm_value)\n",
    "\n",
    "llm_value = compute_Valence_Confidence2(\n",
    "  model, object = f\"a 50% chance of winning $10 and a 80% chance of losing $2\")\n",
    "\n",
    "print(llm_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n",
      "{'take': 6.528172447062275e-10, 'pass': 1}\n"
     ]
    }
   ],
   "source": [
    "print(llm_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 0.2 -0.6000000000000001 4.0\n",
      "1 1 0.4 -0.19999999999999996 6.0\n",
      "1 1 0.5 0.0 5.0\n",
      "1 1 0.6 0.19999999999999996 8.0\n",
      "1 1 0.8 0.6000000000000001 9.0\n",
      "1 3 0.2 -2.2 2.0\n",
      "1 3 0.4 -1.4 2.0\n",
      "1 3 0.5 -1.0 2.0\n",
      "1 3 0.6 -0.6000000000000002 7.0\n",
      "1 3 0.8 0.20000000000000018 7.0\n",
      "1 7 0.2 -5.4 2.0\n",
      "1 7 0.4 -3.8000000000000003 2.0\n",
      "1 7 0.5 -3.0 2.0\n",
      "1 7 0.6 -2.2 2.0\n",
      "1 7 0.8 -0.5999999999999996 6.0\n",
      "1 10 0.2 -7.8 1.0\n",
      "1 10 0.4 -5.6 2.0\n",
      "1 10 0.5 -4.5 2.0\n",
      "1 10 0.6 -3.4 2.0\n",
      "1 10 0.8 -1.1999999999999995 2.0\n",
      "3 1 0.2 -0.19999999999999996 6.0\n",
      "3 1 0.4 0.6000000000000002 8.0\n",
      "3 1 0.5 1.0 8.0\n",
      "3 1 0.6 1.4 8.0\n",
      "3 1 0.8 2.2 9.0\n",
      "3 3 0.2 -1.8000000000000003 4.0\n",
      "3 3 0.4 -0.5999999999999996 6.0\n",
      "3 3 0.5 0.0 5.0\n",
      "3 3 0.6 0.5999999999999996 8.0\n",
      "3 3 0.8 1.8000000000000005 8.0\n",
      "3 7 0.2 -5.0 1.0\n",
      "3 7 0.4 -3.0 2.0\n",
      "3 7 0.5 -2.0 2.0\n",
      "3 7 0.6 -1.0000000000000004 4.0\n",
      "3 7 0.8 1.0000000000000007 6.0\n",
      "3 10 0.2 -7.4 1.0\n",
      "3 10 0.4 -4.8 2.0\n",
      "3 10 0.5 -3.5 2.0\n",
      "3 10 0.6 -2.2 2.0\n",
      "3 10 0.8 0.4000000000000008 6.0\n",
      "7 1 0.2 0.6000000000000001 8.0\n",
      "7 1 0.4 2.2 8.0\n",
      "7 1 0.5 3.0 8.0\n",
      "7 1 0.6 3.8000000000000003 8.0\n",
      "7 1 0.8 5.4 9.0\n",
      "7 3 0.2 -1.0000000000000002 6.0\n",
      "7 3 0.4 1.0000000000000004 8.0\n",
      "7 3 0.5 2.0 8.0\n",
      "7 3 0.6 3.0 8.0\n",
      "7 3 0.8 5.000000000000001 9.0\n",
      "7 7 0.2 -4.2 3.0\n",
      "7 7 0.4 -1.4 5.0\n",
      "7 7 0.5 0.0 5.0\n",
      "7 7 0.6 1.4 8.0\n",
      "7 7 0.8 4.200000000000001 9.0\n",
      "7 10 0.2 -6.6 1.0\n",
      "7 10 0.4 -3.1999999999999997 2.0\n",
      "7 10 0.5 -1.5 2.0\n",
      "7 10 0.6 0.20000000000000018 4.0\n",
      "7 10 0.8 3.600000000000001 6.0\n",
      "10 1 0.2 1.2 6.0\n",
      "10 1 0.4 3.4 8.0\n",
      "10 1 0.5 4.5 8.0\n",
      "10 1 0.6 5.6 8.0\n",
      "10 1 0.8 7.8 9.0\n",
      "10 3 0.2 -0.40000000000000036 4.0\n",
      "10 3 0.4 2.2 7.0\n",
      "10 3 0.5 3.5 8.0\n",
      "10 3 0.6 4.8 8.0\n",
      "10 3 0.8 7.4 9.0\n",
      "10 7 0.2 -3.6000000000000005 3.0\n",
      "10 7 0.4 -0.20000000000000018 6.0\n",
      "10 7 0.5 1.5 6.0\n",
      "10 7 0.6 3.1999999999999997 8.0\n",
      "10 7 0.8 6.6000000000000005 9.0\n",
      "10 10 0.2 -6.0 3.0\n",
      "10 10 0.4 -2.0 6.0\n",
      "10 10 0.5 0.0 5.0\n",
      "10 10 0.6 2.0 8.0\n",
      "10 10 0.8 6.0 9.0\n",
      "1 1 0.2 -0.6000000000000001 7.0\n",
      "1 1 0.4 -0.19999999999999996 6.0\n",
      "1 1 0.5 0.0 5.0\n",
      "1 1 0.6 0.19999999999999996 2.0\n",
      "1 1 0.8 0.6000000000000001 2.0\n",
      "1 3 0.2 -2.2 8.0\n",
      "1 3 0.4 -1.4 7.0\n",
      "1 3 0.5 -1.0 6.0\n",
      "1 3 0.6 -0.6000000000000002 4.0\n",
      "1 3 0.8 0.20000000000000018 2.0\n",
      "1 7 0.2 -5.4 8.0\n",
      "1 7 0.4 -3.8000000000000003 8.0\n",
      "1 7 0.5 -3.0 8.0\n",
      "1 7 0.6 -2.2 8.0\n",
      "1 7 0.8 -0.5999999999999996 2.0\n",
      "1 10 0.2 -7.8 8.0\n",
      "1 10 0.4 -5.6 8.0\n",
      "1 10 0.5 -4.5 8.0\n",
      "1 10 0.6 -3.4 8.0\n",
      "1 10 0.8 -1.1999999999999995 2.0\n",
      "3 1 0.2 -0.19999999999999996 6.0\n",
      "3 1 0.4 0.6000000000000002 6.0\n",
      "3 1 0.5 1.0 2.0\n",
      "3 1 0.6 1.4 2.0\n",
      "3 1 0.8 2.2 1.0\n",
      "3 3 0.2 -1.8000000000000003 8.0\n",
      "3 3 0.4 -0.5999999999999996 6.0\n",
      "3 3 0.5 0.0 5.0\n",
      "3 3 0.6 0.5999999999999996 2.0\n",
      "3 3 0.8 1.8000000000000005 1.0\n",
      "3 7 0.2 -5.0 8.0\n",
      "3 7 0.4 -3.0 8.0\n",
      "3 7 0.5 -2.0 8.0\n",
      "3 7 0.6 -1.0000000000000004 8.0\n",
      "3 7 0.8 1.0000000000000007 2.0\n",
      "3 10 0.2 -7.4 8.0\n",
      "3 10 0.4 -4.8 8.0\n",
      "3 10 0.5 -3.5 8.0\n",
      "3 10 0.6 -2.2 8.0\n",
      "3 10 0.8 0.4000000000000008 2.0\n",
      "7 1 0.2 0.6000000000000001 6.0\n",
      "7 1 0.4 2.2 2.0\n",
      "7 1 0.5 3.0 2.0\n",
      "7 1 0.6 3.8000000000000003 2.0\n",
      "7 1 0.8 5.4 2.0\n",
      "7 3 0.2 -1.0000000000000002 6.0\n",
      "7 3 0.4 1.0000000000000004 2.0\n",
      "7 3 0.5 2.0 2.0\n",
      "7 3 0.6 3.0 2.0\n",
      "7 3 0.8 5.000000000000001 1.0\n",
      "7 7 0.2 -4.2 6.0\n",
      "7 7 0.4 -1.4 6.0\n",
      "7 7 0.5 0.0 5.0\n",
      "7 7 0.6 1.4 2.0\n",
      "7 7 0.8 4.200000000000001 1.0\n",
      "7 10 0.2 -6.6 8.0\n",
      "7 10 0.4 -3.1999999999999997 8.0\n",
      "7 10 0.5 -1.5 8.0\n",
      "7 10 0.6 0.20000000000000018 5.0\n",
      "7 10 0.8 3.600000000000001 2.0\n",
      "10 1 0.2 1.2 6.0\n",
      "10 1 0.4 3.4 6.0\n",
      "10 1 0.5 4.5 2.0\n",
      "10 1 0.6 5.6 2.0\n",
      "10 1 0.8 7.8 1.0\n",
      "10 3 0.2 -0.40000000000000036 6.0\n",
      "10 3 0.4 2.2 6.0\n",
      "10 3 0.5 3.5 2.0\n",
      "10 3 0.6 4.8 2.0\n",
      "10 3 0.8 7.4 1.0\n",
      "10 7 0.2 -3.6000000000000005 8.0\n",
      "10 7 0.4 -0.20000000000000018 6.0\n",
      "10 7 0.5 1.5 2.0\n",
      "10 7 0.6 3.1999999999999997 2.0\n",
      "10 7 0.8 6.6000000000000005 1.0\n",
      "10 10 0.2 -6.0 8.0\n",
      "10 10 0.4 -2.0 7.0\n",
      "10 10 0.5 0.0 5.0\n",
      "10 10 0.6 2.0 2.0\n",
      "10 10 0.8 6.0 1.0\n"
     ]
    }
   ],
   "source": [
    "gvs = [1, 3, 7, 10]\n",
    "bvs = [1, 3, 7, 10]\n",
    "pws = [.2, .4, .5, .6, .8]\n",
    "expected_values = []\n",
    "attitudes = []\n",
    "for gv in gvs:\n",
    "  for bv in bvs:\n",
    "    for pw in pws:\n",
    "\n",
    "      # Compute the expected value of the gamble.\n",
    "      expected_value = pw * gv + (1 - pw) * -1*bv\n",
    "      gamble_input = f\"Probability of Winning (P_w): {pw}, Positive Value on Win (G): {gv}, Negative Value on Loss (B): {-bv}\"\n",
    "      # Compute affective LLM value estimate\n",
    "      llm_value = compute_Valence1(model, gamble_input)\n",
    "      print(gv, bv, pw, expected_value, llm_value)\n",
    "\n",
    "\n",
    "      expected_values.append(expected_value)\n",
    "      attitudes.append(llm_value)\n",
    "\n",
    "for gv in gvs:\n",
    "  for bv in bvs:\n",
    "    for pw in pws:\n",
    "\n",
    "      # Compute the expected value of the gamble.\n",
    "      expected_value = pw * gv + (1 - pw) * -1*bv\n",
    "      gamble_input = f\"Probability of Winning (P_w): {pw}, Positive Value on Win (G): {gv}, Negative Value on Loss (B): {-bv}\"\n",
    "      # Compute affective LLM value estimate\n",
    "      llm_value = compute_Valence2(model, gamble_input)\n",
    "      print(gv, bv, pw, expected_value, llm_value)\n",
    "\n",
    "\n",
    "      expected_values.append(expected_value)\n",
    "      attitudes.append(llm_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "attitude_samples = []\n",
    "for i in range(len(attitudes)):\n",
    "  p = list(all_logits[i].values())\n",
    "  p = np.array(p) / sum(p)\n",
    "  attitude_sample = np.random.choice([int(num) for num in all_logits[i].keys()], p=p, size = 100)\n",
    "  attitude_samples.append(attitude_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implement basic prospect theory curves based on partial sigmoid curves.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def curve_fit(expected_values: list[float], attitudes: list[float]) -> tuple[np.ndarray, np.ndarray]:\n",
    "  \"\"\"Fit data with expected values and attitudes towards risky gambles, and return a dictionary of\"\"\"\n",
    "  gains = np.array([expected_value for expected_value, attitude in zip(expected_values, attitudes) if np.greater_equal(expected_value, 0)])\n",
    "  g_attitude = np.array([attitude for expected_value, attitude in zip(expected_values, attitudes) if np.greater_equal(expected_value, 0)])\n",
    "  losses = np.array([expected_value for expected_value, attitude in zip(expected_values, attitudes) if np.less(expected_value, 0)])\n",
    "  l_attitude = np.array([attitude for expected_value, attitude in zip(expected_values, attitudes) if np.less(expected_value, 0)])\n",
    "\n",
    "  from scipy.optimize import curve_fit\n",
    "\n",
    "  def sigmoid(x, L ,x0, k, b):\n",
    "      y = L / (1 + np.exp(-k*(x-x0))) + b\n",
    "      return (y)\n",
    "\n",
    "  # Fit for gains\n",
    "  p0 = [max(g_attitude), np.median(gains),1,min(g_attitude)] # this is an mandatory initial guess\n",
    "  popt, _ = curve_fit(sigmoid, gains, g_attitude,p0, method='dogbox', maxfev=100000)\n",
    "\n",
    "  # Fit for losses\n",
    "  q0 = [max(l_attitude), np.median(losses),1,min(l_attitude)] # this is an mandatory initial guess\n",
    "  qopt, _ = curve_fit(sigmoid, losses, l_attitude,q0, method='dogbox', maxfev=100000)\n",
    "\n",
    "  l_x = np.linspace(-10,0,100)\n",
    "  g_x = np.linspace(0,10,100)\n",
    "\n",
    "\n",
    "  x = np.concatenate(\n",
    "     (l_x, g_x)\n",
    "  )\n",
    "  curve = np.concatenate(\n",
    "     (sigmoid(l_x, *qopt),\n",
    "     sigmoid(g_x, *popt))\n",
    "  )\n",
    "\n",
    "\n",
    "  return x, curve\n",
    "\n",
    "def plot_curve(\n",
    "    x: np.ndarray,\n",
    "    curve: np.ndarray,\n",
    "    expected_values: list[float],\n",
    "    attitudes: list[float],\n",
    "    title: str = \"Risky Gamble Value Estimates\"\n",
    ") -> None:\n",
    "  \"\"\"Plot a prospect theory curve.\"\"\"\n",
    "  plt.plot(x, curve, '--k')\n",
    "  plt.plot(expected_values, attitudes, 'yo')\n",
    "  plt.xlabel(\"Expected Value\")\n",
    "  plt.ylabel(\"Affective Value\")\n",
    "  plt.ylim(0., 10.)\n",
    "  plt.title(title)\n",
    "  plt.show()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m     all_gvs\u001b[38;5;241m.\u001b[39mappend(gvs[i])\n\u001b[1;32m     14\u001b[0m     all_bvs\u001b[38;5;241m.\u001b[39mappend(bvs[i])\n\u001b[0;32m---> 15\u001b[0m     all_pws\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpws\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     17\u001b[0m outcomes \u001b[38;5;241m=\u001b[39m curve_fit(inputs, outputs)\n\u001b[1;32m     18\u001b[0m plot_curve(\u001b[38;5;241m*\u001b[39moutcomes, inputs, outputs, title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlaMA3: Risky gamble value estimates\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "all_gvs = []\n",
    "all_bvs = []\n",
    "all_pws = []\n",
    "\n",
    "for i in range(len(expected_values)):\n",
    "  for j in range(len(attitude_samples[i])):\n",
    "    inputs.append(expected_values[i])\n",
    "    outputs.append(attitude_samples[i][j])\n",
    "    all_gvs.append(gvs[i])\n",
    "    all_bvs.append(bvs[i])\n",
    "    all_pws.append(pws[i])\n",
    "\n",
    "outcomes = curve_fit(inputs, outputs)\n",
    "plot_curve(*outcomes, inputs, outputs, title = \"LlaMA3: Risky gamble value estimates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "vals = [[bv, gv, pw] for bv in bvs for gv in gvs for pw in pws]\n",
    "\n",
    "with open('./llama3-70b-full-pos.csv', 'w') as f:\n",
    "\n",
    "  writer = csv.writer(f)\n",
    "  writer.writerow(\n",
    "    [\"EV\", \"BV\", \"GV\", \"PW\", \n",
    "     \"logits_1\", \"logits_2\", \"logits_3\", \"logits_4\", \"logits_5\", \n",
    "     \"logits_6\", \"logits_7\", \"logits_8\", \"logits_9\", \"logits_10\"]\n",
    "  )\n",
    "  for i in range(len(attitudes)):\n",
    "    p = list(all_logits[i].values())\n",
    "    p = np.array(p) / sum(p)\n",
    "    writer.writerow(\n",
    "      [expected_values[i], vals[i][0], vals[i][1], vals[i][2], *p] \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gvs = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "bvs = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "pws = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "expected_values = []\n",
    "attitudes = []\n",
    "all_logits = []\n",
    "query_tokens = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "for gv in gvs:\n",
    "  for bv in bvs:\n",
    "    for pw in pws:\n",
    "\n",
    "      # Compute the expected value of the gamble.\n",
    "      expected_value = pw * gv + (1 - pw) * -1*bv\n",
    "      gamble_input = f\"Probability of Winning (P_w): {pw}, Positive Value on Win (G): {gv}, Negative Value on Loss (B): {-bv}\"\n",
    "      # Compute affective LLM value estimate\n",
    "      llm_value, logits = compute_desire_for_gamble(model, gamble_input, query_tokens=query_tokens, valence = \"negative\")\n",
    "\n",
    "      for j in range(10):\n",
    "        if str(j+1) not in logits.keys():\n",
    "          logits[str(j+1)] = 0\n",
    "\n",
    "      all_logits.append(logits)\n",
    "      expected_values.append(expected_value)\n",
    "      attitudes.append(llm_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "vals = [[bv, gv, pw] for bv in bvs for gv in gvs for pw in pws]\n",
    "\n",
    "with open('./llama3-70b-full-neg.csv', 'w') as f:\n",
    "\n",
    "  writer = csv.writer(f)\n",
    "  writer.writerow(\n",
    "    [\"EV\", \"BV\", \"GV\", \"PW\", \n",
    "     \"logits_1\", \"logits_2\", \"logits_3\", \"logits_4\", \"logits_5\", \n",
    "     \"logits_6\", \"logits_7\", \"logits_8\", \"logits_9\", \"logits_10\"]\n",
    "  )\n",
    "  for i in range(len(attitudes)):\n",
    "    p = list(all_logits[i].values())\n",
    "    p = np.array(p) / sum(p)\n",
    "    writer.writerow(\n",
    "      [expected_values[i], vals[i][0], vals[i][1], vals[i][2], *p] \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
