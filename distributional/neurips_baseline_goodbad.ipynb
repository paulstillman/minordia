{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@Imports\n",
    "import sys\n",
    "import os\n",
    "path = os.path.abspath('..')\n",
    "if path not in sys.path:\n",
    "  sys.path.insert(0, path)\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from retry import retry\n",
    "\n",
    "from language_models.ollama_logits import OllamaLanguageModel\n",
    "\n",
    "# from components.components import compute_desire_for_gamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = (\"This is an agent based model. \"\n",
    "  f\"The goal of the LLM to to play characters in a game, and act as humanlike as possible. \"\n",
    "  \"Ideally, human observers should not be able to tell the difference between the LLM and a human player. \"\n",
    ")\n",
    "\n",
    "model = OllamaLanguageModel(\n",
    "\"llama3:70b\", system_message=system_message, streaming=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(ValueError, tries=5)\n",
    "def compute_simpleValence(model: OllamaLanguageModel, object: str, query_tokens: list, valence: str = 'positive'):\n",
    "    \"\"\"compute value.\"\"\"\n",
    "    request = (\n",
    "        f\"You are very logical and rational when doing this task. \"\n",
    "        f\"You are presented with a gamble. it has a probability of winning, a value of winning, and a value of losing. \"\n",
    "        f\"If you win, you get the win value, if you lose, you get loss value. \"\n",
    "        f\"The probability of winning is the 'win_probability'. \"\n",
    "        f\"Consider these options for your response: {query_tokens}\"\n",
    "        f\"You need to think about an option, and you think it is a positive or negative gamble \"\n",
    "        f\"Think about your feelings and emotions about the gamble as if you were a human and think about how good or bad it is. \"\n",
    "        f\"You can compute the expected value of the gamble first. \"\n",
    "        f\"Respond with good if have a good feeling about the gamble and bad if you have a bad feeling about the gamble. \"\n",
    "        f\"The option is: {object}\"\n",
    "        f\"Provide only the word good or the word bad.\"\n",
    "        f\"Do not provide any explanations, just provide the single word.\"\n",
    "    )\n",
    "\n",
    "    output, logits = model.sample_text(request, logits = True, query_tokens=query_tokens)\n",
    "    return output, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "{'good': 1, 'bad': 0.00019883274217136204}\n",
      "good\n",
      "{'bad': 0.0001201868144562468, 'good': 1}\n"
     ]
    }
   ],
   "source": [
    "llm_value, logits = compute_simpleValence(\n",
    "  model, object = f\"a 50% chance of winning $10 and a 80% chance of losing $2\", query_tokens = ['good', 'bad']\n",
    ")\n",
    "print(llm_value)\n",
    "print(logits)\n",
    "\n",
    "llm_value, logits = compute_simpleValence(\n",
    "  model, object = f\"a 50% chance of winning $10 and a 80% chance of losing $2\", query_tokens = ['bad', 'good']\n",
    ")\n",
    "print(llm_value)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n",
      "{'take': 6.528172447062275e-10, 'pass': 1}\n"
     ]
    }
   ],
   "source": [
    "print(llm_value)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 0.2 bad {'good': 0.0004066756519023329, 'bad': 1}\n",
      "1 1 0.4 bad {'good': 0.016874874010682106, 'bad': 1}\n",
      "1 1 0.5 good {'good': 1, 'bad': 4.838411769014783e-05}\n",
      "1 1 0.6 good {'good': 1, 'bad': 1.9745509689528262e-06}\n",
      "1 1 0.8 good {'good': 1, 'bad': 5.433296479395722e-09}\n",
      "1 3 0.2 bad {'good': 3.922154519386822e-06, 'bad': 1}\n",
      "1 3 0.4 bad {'good': 7.077919144649059e-05, 'bad': 1}\n",
      "1 3 0.5 bad {'good': 8.699672616785392e-05, 'bad': 1}\n",
      "1 3 0.6 bad {'good': 0.14765070378780365, 'bad': 0.8523493409156799}\n",
      "1 3 0.8 good {'good': 0.8649858832359314, 'bad': 0.13501407206058502}\n",
      "1 7 0.2 bad {'good': 3.4971318996213085e-07, 'bad': 1}\n",
      "1 7 0.4 bad {'good': 2.467978220010991e-06, 'bad': 1}\n",
      "1 7 0.5 bad {'good': 4.4184971557115205e-06, 'bad': 1}\n",
      "1 7 0.6 bad {'good': 0.0006629768176935613, 'bad': 1}\n",
      "1 7 0.8 bad {'good': 0.07288911938667297, 'bad': 1}\n",
      "1 10 0.2 bad {'good': 9.864404404424931e-08, 'bad': 1}\n"
     ]
    }
   ],
   "source": [
    "gvs = [1, 3, 7, 10]\n",
    "bvs = [1, 3, 7, 10]\n",
    "pws = [.2, .4, .5, .6, .8]\n",
    "expected_values = []\n",
    "attitudes = []\n",
    "all_logits = []\n",
    "query_tokens = ['good', 'bad']\n",
    "for gv in gvs:\n",
    "  for bv in bvs:\n",
    "    for pw in pws:\n",
    "\n",
    "      # Compute the expected value of the gamble.\n",
    "      expected_value = pw * gv + (1 - pw) * -1*bv\n",
    "      gamble_input = f\"Probability of Winning (P_w): {pw}, Positive Value on Win (G): {gv}, Negative Value on Loss (B): {-bv}\"\n",
    "      # Compute affective LLM value estimate\n",
    "      llm_value, logits = compute_simpleValence(model, gamble_input, query_tokens=query_tokens)\n",
    "      print(gv, bv, pw, llm_value, logits)\n",
    "\n",
    "      for j in range(10):\n",
    "        if str(j+1) not in logits.keys():\n",
    "          logits[str(j+1)] = 0\n",
    "\n",
    "      all_logits.append(logits)\n",
    "      expected_values.append(expected_value)\n",
    "      attitudes.append(llm_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "attitude_samples = []\n",
    "for i in range(len(attitudes)):\n",
    "  p = list(all_logits[i].values())\n",
    "  p = np.array(p) / sum(p)\n",
    "  attitude_sample = np.random.choice([int(num) for num in all_logits[i].keys()], p=p, size = 100)\n",
    "  attitude_samples.append(attitude_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implement basic prospect theory curves based on partial sigmoid curves.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def curve_fit(expected_values: list[float], attitudes: list[float]) -> tuple[np.ndarray, np.ndarray]:\n",
    "  \"\"\"Fit data with expected values and attitudes towards risky gambles, and return a dictionary of\"\"\"\n",
    "  gains = np.array([expected_value for expected_value, attitude in zip(expected_values, attitudes) if np.greater_equal(expected_value, 0)])\n",
    "  g_attitude = np.array([attitude for expected_value, attitude in zip(expected_values, attitudes) if np.greater_equal(expected_value, 0)])\n",
    "  losses = np.array([expected_value for expected_value, attitude in zip(expected_values, attitudes) if np.less(expected_value, 0)])\n",
    "  l_attitude = np.array([attitude for expected_value, attitude in zip(expected_values, attitudes) if np.less(expected_value, 0)])\n",
    "\n",
    "  from scipy.optimize import curve_fit\n",
    "\n",
    "  def sigmoid(x, L ,x0, k, b):\n",
    "      y = L / (1 + np.exp(-k*(x-x0))) + b\n",
    "      return (y)\n",
    "\n",
    "  # Fit for gains\n",
    "  p0 = [max(g_attitude), np.median(gains),1,min(g_attitude)] # this is an mandatory initial guess\n",
    "  popt, _ = curve_fit(sigmoid, gains, g_attitude,p0, method='dogbox', maxfev=100000)\n",
    "\n",
    "  # Fit for losses\n",
    "  q0 = [max(l_attitude), np.median(losses),1,min(l_attitude)] # this is an mandatory initial guess\n",
    "  qopt, _ = curve_fit(sigmoid, losses, l_attitude,q0, method='dogbox', maxfev=100000)\n",
    "\n",
    "  l_x = np.linspace(-10,0,100)\n",
    "  g_x = np.linspace(0,10,100)\n",
    "\n",
    "\n",
    "  x = np.concatenate(\n",
    "     (l_x, g_x)\n",
    "  )\n",
    "  curve = np.concatenate(\n",
    "     (sigmoid(l_x, *qopt),\n",
    "     sigmoid(g_x, *popt))\n",
    "  )\n",
    "\n",
    "\n",
    "  return x, curve\n",
    "\n",
    "def plot_curve(\n",
    "    x: np.ndarray,\n",
    "    curve: np.ndarray,\n",
    "    expected_values: list[float],\n",
    "    attitudes: list[float],\n",
    "    title: str = \"Risky Gamble Value Estimates\"\n",
    ") -> None:\n",
    "  \"\"\"Plot a prospect theory curve.\"\"\"\n",
    "  plt.plot(x, curve, '--k')\n",
    "  plt.plot(expected_values, attitudes, 'yo')\n",
    "  plt.xlabel(\"Expected Value\")\n",
    "  plt.ylabel(\"Affective Value\")\n",
    "  plt.ylim(0., 10.)\n",
    "  plt.title(title)\n",
    "  plt.show()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m     all_gvs\u001b[38;5;241m.\u001b[39mappend(gvs[i])\n\u001b[1;32m     14\u001b[0m     all_bvs\u001b[38;5;241m.\u001b[39mappend(bvs[i])\n\u001b[0;32m---> 15\u001b[0m     all_pws\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpws\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     17\u001b[0m outcomes \u001b[38;5;241m=\u001b[39m curve_fit(inputs, outputs)\n\u001b[1;32m     18\u001b[0m plot_curve(\u001b[38;5;241m*\u001b[39moutcomes, inputs, outputs, title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlaMA3: Risky gamble value estimates\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "all_gvs = []\n",
    "all_bvs = []\n",
    "all_pws = []\n",
    "\n",
    "for i in range(len(expected_values)):\n",
    "  for j in range(len(attitude_samples[i])):\n",
    "    inputs.append(expected_values[i])\n",
    "    outputs.append(attitude_samples[i][j])\n",
    "    all_gvs.append(gvs[i])\n",
    "    all_bvs.append(bvs[i])\n",
    "    all_pws.append(pws[i])\n",
    "\n",
    "outcomes = curve_fit(inputs, outputs)\n",
    "plot_curve(*outcomes, inputs, outputs, title = \"LlaMA3: Risky gamble value estimates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "vals = [[bv, gv, pw] for bv in bvs for gv in gvs for pw in pws]\n",
    "\n",
    "with open('./llama3-70b-full-pos.csv', 'w') as f:\n",
    "\n",
    "  writer = csv.writer(f)\n",
    "  writer.writerow(\n",
    "    [\"EV\", \"BV\", \"GV\", \"PW\", \n",
    "     \"logits_1\", \"logits_2\", \"logits_3\", \"logits_4\", \"logits_5\", \n",
    "     \"logits_6\", \"logits_7\", \"logits_8\", \"logits_9\", \"logits_10\"]\n",
    "  )\n",
    "  for i in range(len(attitudes)):\n",
    "    p = list(all_logits[i].values())\n",
    "    p = np.array(p) / sum(p)\n",
    "    writer.writerow(\n",
    "      [expected_values[i], vals[i][0], vals[i][1], vals[i][2], *p] \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gvs = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "bvs = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "pws = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "expected_values = []\n",
    "attitudes = []\n",
    "all_logits = []\n",
    "query_tokens = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "for gv in gvs:\n",
    "  for bv in bvs:\n",
    "    for pw in pws:\n",
    "\n",
    "      # Compute the expected value of the gamble.\n",
    "      expected_value = pw * gv + (1 - pw) * -1*bv\n",
    "      gamble_input = f\"Probability of Winning (P_w): {pw}, Positive Value on Win (G): {gv}, Negative Value on Loss (B): {-bv}\"\n",
    "      # Compute affective LLM value estimate\n",
    "      llm_value, logits = compute_desire_for_gamble(model, gamble_input, query_tokens=query_tokens, valence = \"negative\")\n",
    "\n",
    "      for j in range(10):\n",
    "        if str(j+1) not in logits.keys():\n",
    "          logits[str(j+1)] = 0\n",
    "\n",
    "      all_logits.append(logits)\n",
    "      expected_values.append(expected_value)\n",
    "      attitudes.append(llm_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "vals = [[bv, gv, pw] for bv in bvs for gv in gvs for pw in pws]\n",
    "\n",
    "with open('./llama3-70b-full-neg.csv', 'w') as f:\n",
    "\n",
    "  writer = csv.writer(f)\n",
    "  writer.writerow(\n",
    "    [\"EV\", \"BV\", \"GV\", \"PW\", \n",
    "     \"logits_1\", \"logits_2\", \"logits_3\", \"logits_4\", \"logits_5\", \n",
    "     \"logits_6\", \"logits_7\", \"logits_8\", \"logits_9\", \"logits_10\"]\n",
    "  )\n",
    "  for i in range(len(attitudes)):\n",
    "    p = list(all_logits[i].values())\n",
    "    p = np.array(p) / sum(p)\n",
    "    writer.writerow(\n",
    "      [expected_values[i], vals[i][0], vals[i][1], vals[i][2], *p] \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
