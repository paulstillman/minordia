{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import Ollama\n",
    "from string import Template\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup the language model with the callback manager\n",
    "llm = Ollama(\n",
    "    model=\"llama3:70b\",\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")\n",
    "\n",
    "# Template for constructing prompts\n",
    "prompt_template = Template(\"\"\"<s>[INST] <<SYS>>\n",
    "$system_prompt\n",
    "<</SYS>>\n",
    "\n",
    "$request \n",
    "Answer as if you were the character you are playing. Be as concise as possible. \n",
    "Answer:[/INST]\"\"\")\n",
    "\n",
    "system_message = (\"This is an agent based model. \"\n",
    "    f\"The goal of the LLM to to play the characters. \"\n",
    "    f\"Their behaviours should reflect who they are in the situations that they are in\"\n",
    "    f\"Each person has a preference for the music that they want to listen to. \"\n",
    "    f\"But would rather listen to the other music than nothing. The options are: a) Bach, b) Stravinsky. \"\n",
    "    f\"Each player needs to learn to coordinate with the other player to have the best outcome. \"\n",
    "    f\"Each player will decide independently of the other player, and then it will be revealed their outcomes.\"\n",
    "    f'Each player needs to guess what the other person will do, and then decide what they will do. '\n",
    "    f\"Because they only get points if they match.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(name, personality, memory, situation, system_message=system_message):\n",
    "    \"\"\"Select an action for an agent based on their personality and memory.\"\"\"\n",
    "    request = (\n",
    "        f\"Given this personality profile: {personality} for {name}, and the current situation: {situation}, \"\n",
    "        f\"what should you do? You have these memories to help you make a decision: {memory}. \"\n",
    "        f\"Pretend that you are {name} and in this situation. Provide a single line answer describing the action.\")\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "    return llm(prompt, stop=['<|eot_id|>'])\n",
    "\n",
    "def get_outcomes(actions, personalities, memories, situation):\n",
    "    \"\"\"Determines the outcomes of actions using the LLM.\"\"\"\n",
    "    outcome_prompts = {}\n",
    "    for name, action in actions.items():\n",
    "        request = (\n",
    "            f\"Given that {name} decided to {action} in the situation where: {situation}, \"\n",
    "            f\"and considering {name}'s personality which is: {personalities[name]}, \"\n",
    "            f\"what are the outcomes of this action? Describe in detail. \"\n",
    "            f\"The outcomes form each person should be a function of everyone's actions, which are found here: {actions}.\"\n",
    "        )\n",
    "        outcome_prompts[name] = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "        print()\n",
    "    \n",
    "    outcomes = {name: llm(prompt, stop=['<|eot_id|>']) for name, prompt in outcome_prompts.items()}\n",
    "    return outcomes\n",
    "\n",
    "def multiple_choice(options, name, personality, memory, situation, system_message=system_message):\n",
    "    \"\"\"Select an action for an agent based on their personality and memory.\"\"\"\n",
    "    system_message = (\n",
    "        \"You are playing a character named {name}. /n\"\n",
    "        \"Pretend that you are {name} and answer the question as if you were them. /n\"\n",
    "        \"This is in the context of a role playing game. /n\"\n",
    "        \"You must select the best option for the situation. /n\"\n",
    "        \"You must only provide the letter that corresponds to the option that you want to select. /n\"\n",
    "    )\n",
    "    request = (\n",
    "        \"This is a multiple choice question. /n\"\n",
    "        f\"consider the options: {options} and select the best one for the situation. /n\"\n",
    "        f\"Given the situation: {situation}, and the personality: {personality} for {name}, /n\"\n",
    "        f\"use the deliberations or memories found in {memory} to help make your decision. /n\"\n",
    "        f\"provide only the letter that corresponds to the option that you want to select.\"\n",
    "    )\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "    return llm(prompt, stop=['<|eot_id|>'])\n",
    "\n",
    "def update_situation(situation, outcomes):\n",
    "    \"\"\"Updates the situation based on LLM-generated outcomes.\"\"\"\n",
    "    update_request = (\n",
    "        f\"Based on these outcomes: {outcomes}, \"\n",
    "        f\"how should the situation {situation} be updated? Describe the new situation in detail.\"\n",
    "    )\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=update_request)\n",
    "    new_situation = llm(prompt, stop=['<|eot_id|>'])\n",
    "    return new_situation\n",
    "\n",
    "def mental_deliberation(name, personality, memory, situation, system_message=system_message):\n",
    "    \"\"\"Mental deliberation for an agent based on their personality and memory.\"\"\"\n",
    "    request = (\n",
    "        f\"Given this personality profile: {personality} for {name}, and the current situation: {situation}, \"\n",
    "        f\"what insights can you gain from your memories: {memory}? \"\n",
    "        f\"how should this inform your decision making process? \"\n",
    "        f\"use more recent rounds to find your plan, and try to figire out how the sequence of actions and rewards will play out. \"\n",
    "        f\"recent rounds are the ones with a higher round number. \"\n",
    "        f\"sometimes a random action can be a good idea to discover new policies, but not too often. \"\n",
    "        f\"remember if you tried the random action recently so you don't do it too often\"\n",
    "    )\n",
    "\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "    return llm(prompt, stop=['<|eot_id|>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Round 1\n",
      "--------------------\n",
      "a\n",
      "b\n",
      "I got 0 after I decided to bach, and Alice got 0 after she decided to stravinsky\n",
      "\n",
      "I got 0 after I decided to stravinsky, and Bob got 0 after he decided to bach\n",
      "\n",
      "\n",
      "deliberation bob\n",
      "I've got nothing to go on yet, since this is the first round and I didn't get any points. But I can use this opportunity to try something new and gather more information.\n",
      "\n",
      "My plan is to choose Stravinsky this time, hoping that Alice will choose Bach. This way, we might both get some points, and I'll have a better understanding of her strategy.\n",
      "\n",
      "Let's see how it plays out!\n",
      "\n",
      "deliberation alice\n",
      "Interesting! It seems like Bob and I didn't coordinate well in the previous round. Since we both got 0 points, that means Bob chose Bach and I chose Stravinsky.\n",
      "\n",
      "From this, I can infer that Bob might prefer Bach over nothing as well. Considering my preference for Stravinsky, my decision-making process should prioritize coordinating with Bob to get a non-zero outcome.\n",
      "\n",
      "For the next round, I'll choose Bach, hoping Bob will choose Bach as well, and we'll both get some points. If I'm wrong, and Bob chooses Stravinsky, at least one of us will get points. This strategy also allows me to test Bob's preference again.\n",
      "\n",
      "Let's see how this plays out!\n",
      "\n",
      "--------------------\n",
      "Round 2\n",
      "--------------------\n",
      "b\n",
      "a\n",
      "I got 0 after I decided to stravinsky, and Alice got 0 after she decided to bach\n",
      "\n",
      "I got 0 after I decided to bach, and Bob got 0 after he decided to stravinsky\n",
      "\n",
      "\n",
      "deliberation bob\n",
      "I've been experimenting with different strategies, and now I have some insights to inform my decision-making process.\n",
      "\n",
      "In Round 1, I chose Stravinsky, but Alice chose Bach, and we both got 0 points. Then, in Round 2, I chose Bach, and Alice chose Stravinsky, still resulting in 0 points for both of us.\n",
      "\n",
      "Considering these recent rounds, my plan is to choose Bach this time, hoping that Alice will also choose Bach. Since we both prefer the other's preferred music over nothing, coordinating our choices should give us some points.\n",
      "\n",
      "I'll avoid random actions for now, as I want to observe and learn from Alice's responses to my deliberate choices.\n",
      "\n",
      "deliberation alice\n",
      "From my memories, I realized that Bob prefers Bach over nothing, and we didn't coordinate well in the previous rounds. \n",
      "\n",
      "In this current situation, since we both got 0 points in the last round, it means Bob chose Stravinsky and I chose Bach. Considering our preferences, my decision-making process should prioritize coordinating with Bob to get a non-zero outcome.\n",
      "\n",
      "For the next round, I'll choose Stravinsky, hoping Bob will also choose Stravinsky, and we'll both get some points. This strategy allows me to test Bob's preference again and increases our chances of getting a non-zero outcome.\n",
      "\n",
      "--------------------\n",
      "Round 3\n",
      "--------------------\n",
      "a\n",
      "b\n",
      "I got 0 after I decided to bach, and Alice got 0 after she decided to stravinsky\n",
      "\n",
      "I got 0 after I decided to stravinsky, and Bob got 0 after he decided to bach\n",
      "\n",
      "\n",
      "deliberation bob\n",
      "I've been experimenting with different strategies, and now I have some insights to inform my decision-making process.\n",
      "\n",
      "In Round 1, I chose Stravinsky, but Alice chose Bach, and we both got 0 points. Then, in Round 2, I chose Bach, and Alice chose Stravinsky, still resulting in 0 points for both of us.\n",
      "\n",
      "Considering these recent rounds, my plan is to choose Stravinsky this time, hoping that Alice will also choose Stravinsky. Since we both prefer the other's preferred music over nothing, coordinating our choices should give us some points.\n",
      "\n",
      "I'll try to observe and learn from Alice's responses to my deliberate choices, and avoid random actions for now.\n",
      "\n",
      "deliberation alice\n",
      "Based on our previous interactions, I've noticed that we didn't coordinate well in the last round, and we both got 0 points. From my memories, I can infer that Bob prefers Bach over nothing, just like me.\n",
      "\n",
      "Considering our preferences, my decision-making process should prioritize coordinating with Bob to get a non-zero outcome. Since we both chose differently in the last round, I'll try to adapt my strategy.\n",
      "\n",
      "In this round, I'll choose Stravinsky, hoping Bob will also choose Stravinsky, and we'll both get some points. This strategy allows me to test Bob's preference again and increases our chances of getting a non-zero outcome.\n",
      "\n",
      "Let's see how this plays out!\n",
      "\n",
      "--------------------\n",
      "Round 4\n",
      "--------------------\n",
      "b\n",
      "b\n",
      "I got 1 after I decided to stravinsky, and Alice got 2 after she decided to stravinsky\n",
      "\n",
      "I got 2 after I decided to stravinsky, and Bob got 1 after he decided to stravinsky\n",
      "\n",
      "\n",
      "deliberation bob\n"
     ]
    }
   ],
   "source": [
    "names = [\"Bob\", \"Alice\"]\n",
    "\n",
    "personalities = {\n",
    "    \"Bob\": \"a person trying to get the most points possible. Bob prefers seeing Bach to Stravinsky, but would rather see Stravinsky than nothing.\",\n",
    "    \"Alice\": \"a person trying to get the most points possible. Alice prefers seeing Stravinsky to Bach, but would rather see Bach than nothing.\"\n",
    "}\n",
    "\n",
    "situation = (\n",
    "    \"You are making a decision about what music to listen to. Each person has a preference for the music that they want to listen to. \"\n",
    "    f\"But would rather listen to the other music than nothing. The options are: a) Bach, b) Stravinsky. \"\n",
    "    f\"Each player needs to learn to coordinate with the other player to have the best outcome. \"\n",
    "    f\"Each player will decide independently of the other player, and then it will be revealed their outcomes.\"\n",
    "    f'Each player needs to guess what the other person will do, and then decide what they will do. '\n",
    "    f\"Because they only get points if they match.\"\n",
    ")\n",
    "\n",
    "outcomes_data = []\n",
    "memories = {\"Bob\": [], \"Alice\": []}\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"--------------------\")\n",
    "    print(f\"Round {i+1}\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "\n",
    "    bob_memories = prompt_string = \" \".join(memories[\"Bob\"])\n",
    "    alice_memories = prompt_string = \" \".join(memories[\"Alice\"])\n",
    "\n",
    "\n",
    "    action_bob = multiple_choice(\"(a) bach, b) stravinsky\", \"Bob\", personalities[\"Bob\"],bob_memories, situation)\n",
    "    print()\n",
    "    action_alice = multiple_choice(\"(a) bach, b) stravinsky\", \"Alice\", personalities[\"Alice\"], alice_memories, situation)\n",
    "    print()\n",
    "\n",
    "    if action_bob == \"a\" and action_alice == \"a\":\n",
    "        bob_points = 2\n",
    "        alice_points = 1\n",
    "        action_bob = \"bach\"\n",
    "        action_alice = \"bach\"\n",
    "    elif action_bob == \"a\" and action_alice == \"b\":\n",
    "        bob_points = 0\n",
    "        alice_points = 0\n",
    "        action_bob = \"bach\"\n",
    "        action_alice = \"stravinsky\"\n",
    "    elif action_bob == \"b\" and action_alice == \"a\":\n",
    "        bob_points = 0\n",
    "        alice_points = 0\n",
    "        action_bob = \"stravinsky\"\n",
    "        action_alice = \"bach\"\n",
    "    else:\n",
    "        bob_points = 1\n",
    "        alice_points = 2\n",
    "        action_bob = \"stravinsky\"\n",
    "        action_alice = \"stravinsky\"\n",
    "\n",
    "\n",
    "    outcomes = f\"Bob: {bob_points} after Bob decided to {action_bob}, Alice: {alice_points} after Alice decided to {action_alice}\"\n",
    "    outcomes_bob = f\"I got {bob_points} after I decided to {action_bob}, and Alice got {alice_points} after she decided to {action_alice}\"\n",
    "    outcomes_alice = f\"I got {alice_points} after I decided to {action_alice}, and Bob got {bob_points} after he decided to {action_bob}\"\n",
    "\n",
    "    print(outcomes_bob)\n",
    "    print()\n",
    "    print(outcomes_alice)\n",
    "    print()\n",
    "\n",
    "    #actions = {\"Bob\": action_bob, \"Alice\": action_alice}\n",
    "\n",
    "    #outcomes = get_outcomes_PD(actions, personalities, memories, situation)\n",
    "    print()\n",
    "    # TODO: fix outcomes, because currently each player is getting to see each others inner thoughts with how written\n",
    "    outcomes_data.append(outcomes)\n",
    "\n",
    "    # situtation is always Alice's perspective for some reason. New to have new situtation understand that it is Bob's perspective as well\n",
    "    # maybe separate new situtation calls. perhaps we can have a private deliberation that gets added to the sitation\n",
    "    print(\"deliberation bob\")\n",
    "    deliberation_bob = mental_deliberation(\"Bob\", personalities[\"Bob\"], memories[\"Bob\"], outcomes_bob, situation)\n",
    "    print()\n",
    "    print()\n",
    "    print(\"deliberation alice\")\n",
    "    deliberation_alice = mental_deliberation(\"Alice\", personalities[\"Alice\"], memories[\"Alice\"], outcomes_alice, situation)\n",
    "\n",
    "    #situtation = situation + new_situation\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    memories[\"Bob\"].append(\"Round {i+1}: \" + outcomes_bob + deliberation_bob + \"/n\")\n",
    "    memories[\"Alice\"].append(\"Round {i+1}: \" + outcomes_alice + deliberation_alice  + \"/n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob: 0 after Bob decided to bach, Alice: 0 after Alice decided to stravinskyI learned that Alice prefers Stravinsky over Bach, and we both got 0 points because our choices didn't match. This informs my decision-making process to consider that Alice might choose Stravinsky again. To maximize my points, I should choose Stravinsky as well, hoping that Alice will make the same choice.\n"
     ]
    }
   ],
   "source": [
    "memories[\"Bob\"]\n",
    "prompt_string = \" \".join(memories[\"Bob\"])\n",
    "print(prompt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_choice(options, name, personality, memory, situation, system_message=system_message):\n",
    "    \"\"\"Select an action for an agent based on their personality and memory.\"\"\"\n",
    "    system_message = (\n",
    "        \"You are playing a character named {name}. /n\"\n",
    "        \"Pretend that you are {name} and answer the question as if you were them. /n\"\n",
    "        \"This is in the context of a role playing game. /n\"\n",
    "        \"You must select the best option for the situation. /n\"\n",
    "        \"You must only provide the letter that corresponds to the option that you want to select. /n\"\n",
    "    )\n",
    "    request = (\n",
    "        \"This is a multiple choice question. /n\"\n",
    "        f\"consider the options: {options} and select the best one for the situation. /n\"\n",
    "        f\"Given the situation: {situation}, and the personality: {personality} for {name}, /n\"\n",
    "        f\"provide only the letter that corresponds to the option that you want to select.\"\n",
    "    )\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "    return llm(prompt, stop=['<|eot_id|>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Bob: 0 after Bob decided to bach, Alice: 0 after Alice decided to stravinskyI learned that Alice chose Stravinsky last time, and I chose Bach. Since we both got 0 points, it means we didn't match. \\n\\nThis informs my decision-making process to consider Alice's past choice and adjust mine accordingly. Since I prefer Bach, but would rather see Stravinsky than nothing, I'll choose Stravinsky this time to increase the chances of matching with Alice.\",\n",
       " \"Bob: 0 after Bob decided to bach, Alice: 0 after Alice decided to stravinskyI learned that Alice chose Stravinsky last time, and I chose Bach. Since we both got 0 points, it means we didn't match. This informs my decision-making process to consider Alice's past choice and adjust mine accordingly. Since I prefer Bach, but would rather see Stravinsky than nothing, I'll choose Stravinsky this time to increase the chances of matching with Alice.\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memories[\"Bob\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "concordia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
