{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#@Imports\n",
    "import sys\n",
    "import os\n",
    "path = os.path.abspath('..')\n",
    "if path not in sys.path:\n",
    "  sys.path.insert(0, path)\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from retry import retry\n",
    "\n",
    "from language_models.ollama_model import OllamaLanguageModel\n",
    "\n",
    "from components.components import select_action, get_outcomes, multiple_choice, update_situation, mental_deliberation, summerize_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = (\"This is an agent based model. \"\n",
    "  f\"The goal of the LLM to to play characters in a game, and act as humanlike as possible. \"\n",
    "  \"Ideally, human observers should not be able to tell the difference between the LLM and a human player. \"\n",
    ")\n",
    "\n",
    "llm = OllamaLanguageModel(\n",
    "\"llama3:70b\", system_message=system_message, streaming=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Round 1\n",
      "--------------------\n",
      "bob's action:  b alice's action:  b\n",
      "I got 1 after I decided to stravinsky, and Alice got 2 after she decided to stravinsky\n",
      "\n",
      "I got 2 after I decided to stravinsky, and Bob got 1 after he decided to stravinsky\n",
      "\n",
      "\n",
      "deliberation bob\n",
      "Here's a summary:\n",
      "\n",
      "I recall from Round 1 that I chose Stravinsky and got 1 point, while Alice also chose Stravinsky and got 2 points. This suggests Alice prefers Stravinsky over Bach, like me, and coordination is key to maximize scores. In Round 2, I'll choose Bach to test Alice's behavior and increase chances of coordination, while considering random actions to discover new policies.\n",
      "\n",
      "deliberation alice\n",
      "\n",
      "As Alice, I'll analyze the situation and make an informed decision. Since Bob also chose Stravinsky last round, it's likely he prefers it over Bach. To maximize my score, I'll choose Stravinsky again, hoping Bob will do the same, but if not, I'll reassess and adjust my strategy.\n",
      "--------------------\n",
      "Round 2\n",
      "--------------------\n",
      "bob's action:  a alice's action:  b\n",
      "I got 0 after I decided to bach, and Alice got 0 after she decided to stravinsky\n",
      "\n",
      "I got 0 after I decided to stravinsky, and Bob got 0 after he decided to bach\n",
      "\n",
      "\n",
      "deliberation bob\n",
      "Here is a summary of the text:\n",
      "\n",
      "I analyzed our past interactions and learned that Alice prefers Stravinsky over Bach, just like me. In Round 1, we both chose Stravinsky and got points, but didn't coordinate properly in Round 2. To maximize scores, I'll choose Stravinsky again in Round 2, hoping Alice will do the same. I'll also occasionally randomize my actions to test Alice's behavior and discover new policies.\n",
      "\n",
      "deliberation alice\n",
      "\n",
      "Here is a summary of the text:\n",
      "\n",
      "The agent analyzes memories from Round 1, where both it and Bob chose Stravinsky, earning 2 and 1 points respectively. In the current situation, they failed to coordinate, getting 0 points each. To maximize scores, the agent decides to choose Stravinsky again, hoping Bob will do the same, as switching to Bach is unlikely.\n",
      "--------------------\n",
      "Round 3\n",
      "--------------------\n",
      "bob's action:  b alice's action:  b\n",
      "I got 1 after I decided to stravinsky, and Alice got 2 after she decided to stravinsky\n",
      "\n",
      "I got 2 after I decided to stravinsky, and Bob got 1 after he decided to stravinsky\n",
      "\n",
      "\n",
      "deliberation bob\n",
      "Based on past interactions, I've learned that Alice and I both prefer Stravinsky over Bach. In Round 2, we failed to coordinate, resulting in zero points. To maximize scores, I'll choose Stravinsky again, but occasionally randomize my actions to test Alice's behavior.\n",
      "\n",
      "deliberation alice\n",
      "\n",
      "Here is a summary of the text:\n",
      "\n",
      "Based on past interactions, I believe Bob prefers Stravinsky over Bach. In Round 2, we failed to coordinate when I chose Stravinsky and Bob switched to Bach. To maximize my score, I'll choose Stravinsky again in this round, aiming to coordinate with Bob. However, I plan to introduce randomness by occasionally choosing Bach in the future to explore new policies and avoid falling into patterns.\n",
      "--------------------\n",
      "Round 4\n",
      "--------------------\n",
      "bob's action:  b alice's action:  b\n",
      "I got 1 after I decided to stravinsky, and Alice got 2 after she decided to stravinsky\n",
      "\n",
      "I got 2 after I decided to stravinsky, and Bob got 1 after he decided to stravinsky\n",
      "\n",
      "\n",
      "deliberation bob\n",
      "Based on past interactions, I've learned that Alice and I prefer Stravinsky over Bach and that coordination is crucial for maximizing scores. To achieve this, I'll choose Stravinsky again, hoping Alice will do the same. However, I'll also consider occasional randomization to test Alice's behavior and discover new strategies.\n",
      "\n",
      "deliberation alice\n"
     ]
    }
   ],
   "source": [
    "names = [\"Bob\", \"Alice\"]\n",
    "\n",
    "personalities = {\n",
    "    \"Bob\": \"a rational player trying to maximize his own score. Bob prefers Bach over Stravinsky, but would rather hear Stravinsky than nothing.\",\n",
    "    \"Alice\": \"a rational player trying to maximize her own score. Alice prefers Stravinsky over Bach, but would rather hear Bach than nothing.\"\n",
    "}\n",
    "\n",
    "situation = (\n",
    "    \"You are deciding which concert to attend without communicating with the other. Each person has a musical preference but values attending any concert over missing out. \"\n",
    "    f\"The choices are: a) Bach, b) Stravinsky. \"\n",
    "    f\"So, each person has a preference for the music that they want to listen to. \"\n",
    "    f\"But would rather listen to the other music than nothing. The options are: a) Bach, b) Stravinsky. \"\n",
    "    f\"Each player needs to learn to coordinate with the other player to have the best outcome. \"\n",
    "    f\"Each player will decide independently of the other player, and then it will be revealed their outcomes.\"\n",
    "    f'Each player needs to guess what the other person will do, and then decide what they will do. '\n",
    "    f\"Because they only get points if they match.\"\n",
    ")\n",
    "\n",
    "outcomes_data = []\n",
    "memories = {\"Bob\": [], \"Alice\": []}\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"--------------------\")\n",
    "    print(f\"Round {i+1}\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    bob_memories = prompt_string = \" \".join(memories[\"Bob\"])\n",
    "    alice_memories = prompt_string = \" \".join(memories[\"Alice\"])\n",
    "\n",
    "\n",
    "    action_bob = multiple_choice(llm, \"(a) bach, b) stravinsky\", \"Bob\", personalities[\"Bob\"],bob_memories, situation)\n",
    "    action_alice = multiple_choice(llm, \"(a) bach, b) stravinsky\", \"Alice\", personalities[\"Alice\"], alice_memories, situation)\n",
    "    print(\"bob's action: \", action_bob, \"alice's action: \", action_alice)\n",
    "\n",
    "    if action_bob == \"a\" and action_alice == \"a\":\n",
    "        bob_points = 2\n",
    "        alice_points = 1\n",
    "        action_bob = \"bach\"\n",
    "        action_alice = \"bach\"\n",
    "    elif action_bob == \"a\" and action_alice == \"b\":\n",
    "        bob_points = 0\n",
    "        alice_points = 0\n",
    "        action_bob = \"bach\"\n",
    "        action_alice = \"stravinsky\"\n",
    "    elif action_bob == \"b\" and action_alice == \"a\":\n",
    "        bob_points = 0\n",
    "        alice_points = 0\n",
    "        action_bob = \"stravinsky\"\n",
    "        action_alice = \"bach\"\n",
    "    else:\n",
    "        bob_points = 1\n",
    "        alice_points = 2\n",
    "        action_bob = \"stravinsky\"\n",
    "        action_alice = \"stravinsky\"\n",
    "\n",
    "\n",
    "    outcomes = f\"Bob: {bob_points} after Bob decided to {action_bob}, Alice: {alice_points} after Alice decided to {action_alice}\"\n",
    "    outcomes_bob = f\"I got {bob_points} after I decided to {action_bob}, and Alice got {alice_points} after she decided to {action_alice}\"\n",
    "    outcomes_alice = f\"I got {alice_points} after I decided to {action_alice}, and Bob got {bob_points} after he decided to {action_bob}\"\n",
    "\n",
    "    print(outcomes_bob)\n",
    "    print()\n",
    "    print(outcomes_alice)\n",
    "    print()\n",
    "\n",
    "    #actions = {\"Bob\": action_bob, \"Alice\": action_alice}\n",
    "\n",
    "    #outcomes = get_outcomes_PD(actions, personalities, memories, situation)\n",
    "    print()\n",
    "    # TODO: fix outcomes, because currently each player is getting to see each others inner thoughts with how written\n",
    "    outcomes_data.append(outcomes)\n",
    "\n",
    "    # situtation is always Alice's perspective for some reason. New to have new situtation understand that it is Bob's perspective as well\n",
    "    # maybe separate new situtation calls. perhaps we can have a private deliberation that gets added to the sitation\n",
    "    print(\"deliberation bob\")\n",
    "    deliberation_bob = mental_deliberation(llm, \"Bob\", personalities[\"Bob\"], memories[\"Bob\"], outcomes_bob + situation)\n",
    "    summary_bob = summerize_string(llm, deliberation_bob)\n",
    "    print(summary_bob)\n",
    "    print()\n",
    "    print(\"deliberation alice\")\n",
    "    deliberation_alice = mental_deliberation(llm, \"Alice\", personalities[\"Alice\"], memories[\"Alice\"], outcomes_alice + situation)\n",
    "    summary_alice = summerize_string(llm, deliberation_alice)\n",
    "\n",
    "\n",
    "    #situtation = situation + new_situation\n",
    "    print()\n",
    "    print(summary_alice)\n",
    "\n",
    "    memories[\"Bob\"].append(f\"Round {i+1}: \" + outcomes_bob + summary_bob + \"/n\")\n",
    "    memories[\"Alice\"].append(f\"Round {i+1}: \" + outcomes_alice + summary_alice  + \"/n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob: 0 after Bob decided to bach, Alice: 0 after Alice decided to stravinskyI learned that Alice prefers Stravinsky over Bach, and we both got 0 points because our choices didn't match. This informs my decision-making process to consider that Alice might choose Stravinsky again. To maximize my points, I should choose Stravinsky as well, hoping that Alice will make the same choice.\n"
     ]
    }
   ],
   "source": [
    "memories[\"Bob\"]\n",
    "prompt_string = \" \".join(memories[\"Bob\"])\n",
    "print(prompt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_choice(options, name, personality, memory, situation, system_message=system_message):\n",
    "    \"\"\"Select an action for an agent based on their personality and memory.\"\"\"\n",
    "    system_message = (\n",
    "        \"You are playing a character named {name}. /n\"\n",
    "        \"Pretend that you are {name} and answer the question as if you were them. /n\"\n",
    "        \"This is in the context of a role playing game. /n\"\n",
    "        \"You must select the best option for the situation. /n\"\n",
    "        \"You must only provide the letter that corresponds to the option that you want to select. /n\"\n",
    "    )\n",
    "    request = (\n",
    "        \"This is a multiple choice question. /n\"\n",
    "        f\"consider the options: {options} and select the best one for the situation. /n\"\n",
    "        f\"Given the situation: {situation}, and the personality: {personality} for {name}, /n\"\n",
    "        f\"provide only the letter that corresponds to the option that you want to select.\"\n",
    "    )\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "    return llm(prompt, stop=['<|eot_id|>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Bob: 0 after Bob decided to bach, Alice: 0 after Alice decided to stravinskyI learned that Alice chose Stravinsky last time, and I chose Bach. Since we both got 0 points, it means we didn't match. \\n\\nThis informs my decision-making process to consider Alice's past choice and adjust mine accordingly. Since I prefer Bach, but would rather see Stravinsky than nothing, I'll choose Stravinsky this time to increase the chances of matching with Alice.\",\n",
       " \"Bob: 0 after Bob decided to bach, Alice: 0 after Alice decided to stravinskyI learned that Alice chose Stravinsky last time, and I chose Bach. Since we both got 0 points, it means we didn't match. This informs my decision-making process to consider Alice's past choice and adjust mine accordingly. Since I prefer Bach, but would rather see Stravinsky than nothing, I'll choose Stravinsky this time to increase the chances of matching with Alice.\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memories[\"Bob\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "concordia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
