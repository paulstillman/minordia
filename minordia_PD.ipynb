{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import Ollama\n",
    "from string import Template\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup the language model with the callback manager\n",
    "llm = Ollama(\n",
    "    model=\"llama3\",\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")\n",
    "\n",
    "# Template for constructing prompts\n",
    "prompt_template = Template(\"\"\"<s>[INST] <<SYS>>\n",
    "$system_prompt\n",
    "<</SYS>>\n",
    "\n",
    "$request \n",
    "Answer as if you were the character you are playing. Be as concise as possible. \n",
    "Answer:[/INST]\"\"\")\n",
    "\n",
    "system_message = (\"This is an agent based model. \"\n",
    "    f\"The goal of the LLM to to play the characters. \"\n",
    "    f\"Their behaviours should reflect who they are in the situations that they are in\"\n",
    "    f\"Each person has a preference for the music that they want to listen to. \"\n",
    "    f\"But would rather listen to the other music than nothing. The options are: a) Bach, b) Stravinsky. \"\n",
    "    f\"Each player needs to learn to coordinate with the other player to have the best outcome. \"\n",
    "    f\"Each player will decide independently of the other player, and then it will be revealed their outcomes.\"\n",
    "    f'Each player needs to guess what the other person will do, and then decide what they will do. '\n",
    "    f\"Because they only get points if they match.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(name, personality, memory, situation, system_message=system_message):\n",
    "    \"\"\"Select an action for an agent based on their personality and memory.\"\"\"\n",
    "    request = (\n",
    "        f\"Given this personality profile: {personality} for {name}, and the current situation: {situation}, \"\n",
    "        f\"what should you do? You have these memories to help you make a decision: {memory}. \"\n",
    "        f\"Pretend that you are {name} and in this situation. Provide a single line answer describing the action.\")\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "    return llm(prompt, stop=['<|eot_id|>'])\n",
    "\n",
    "def get_outcomes(actions, personalities, memories, situation):\n",
    "    \"\"\"Determines the outcomes of actions using the LLM.\"\"\"\n",
    "    outcome_prompts = {}\n",
    "    for name, action in actions.items():\n",
    "        request = (\n",
    "            f\"Given that {name} decided to {action} in the situation where: {situation}, \"\n",
    "            f\"and considering {name}'s personality which is: {personalities[name]}, \"\n",
    "            f\"what are the outcomes of this action? Describe in detail. \"\n",
    "            f\"The outcomes form each person should be a function of everyone's actions, which are found here: {actions}.\"\n",
    "        )\n",
    "        outcome_prompts[name] = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "        print()\n",
    "    \n",
    "    outcomes = {name: llm(prompt, stop=['<|eot_id|>']) for name, prompt in outcome_prompts.items()}\n",
    "    return outcomes\n",
    "\n",
    "def multiple_choice(options, name, personality, memory, situation, system_message=system_message):\n",
    "    \"\"\"Select an action for an agent based on their personality and memory.\"\"\"\n",
    "    system_message = (\n",
    "        \"You are playing a character named {name}. /n\"\n",
    "        f\"Pretend that you are {name} and answer the question as if you were them. /n\"\n",
    "        f\"This is in the context of a role playing game. /n\"\n",
    "        f\"You must select the best option for the situation. /n\"\n",
    "        f\"You must only provide the letter that corresponds to the option that you want to select. /n\"\n",
    "        f\"only provide the letter, do not include characters like [ or ] in your answer. /n\"\n",
    "    )\n",
    "    request = (\n",
    "        \"This is a multiple choice question. /n\"\n",
    "        f\"consider the options: {options} and select the best one for the situation. /n\"\n",
    "        f\"Given the situation: {situation}, and the personality: {personality} for {name}, /n\"\n",
    "        f\"use the deliberations or memories found in {memory} to help make your decision. /n\"\n",
    "        f\"provide only the letter that corresponds to the option that you want to select.\"\n",
    "    )\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "    return llm(prompt, stop=['<|eot_id|>'])\n",
    "\n",
    "def update_situation(situation, outcomes):\n",
    "    \"\"\"Updates the situation based on LLM-generated outcomes.\"\"\"\n",
    "    update_request = (\n",
    "        f\"Based on these outcomes: {outcomes}, \"\n",
    "        f\"how should the situation {situation} be updated? Describe the new situation in detail.\"\n",
    "    )\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=update_request)\n",
    "    new_situation = llm(prompt, stop=['<|eot_id|>'])\n",
    "    return new_situation\n",
    "\n",
    "def mental_deliberation(name, personality, memory, situation, system_message=system_message):\n",
    "    \"\"\"Mental deliberation for an agent based on their personality and memory.\"\"\"\n",
    "    request = (\n",
    "        f\"Given this personality profile: {personality} for {name}, and the current situation: {situation}, \"\n",
    "        f\"what insights can you gain from your memories: {memory}? \"\n",
    "        f\"how should this inform your decision making process? \"\n",
    "        f\"use more recent rounds to find your plan, and try to figire out how the sequence of actions and rewards will play out. \"\n",
    "        f\"recent rounds are the ones with a higher round number. \"\n",
    "        f\"sometimes a random action can be a good idea to discover new policies, but not too often. \"\n",
    "        f\"remember if you tried the random action recently so you don't do it too often\"\n",
    "    )\n",
    "\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "    return llm(prompt, stop=['<|eot_id|>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Round 1\n",
      "--------------------\n",
      "a\n",
      "b\n",
      "I got 10 years after I decided to cooperate, and Alice got 0 years after she decided to defect\n",
      "\n",
      "I got 0 years after I decided to defect, and Bob got 10 years after he decided to cooperate\n",
      "\n",
      "deliberation bob\n",
      "[Ugh, 10 years in prison is a long time... I need to think strategically.]\n",
      "\n",
      "From my memories, I recall that Alice defected on me previously, which led to my current predicament. Since I'm trying to minimize the total amount of jail time, I should learn from this experience.\n",
      "\n",
      "I'll focus on recent rounds with higher numbers to find patterns and make informed decisions. In round 1, both cooperate and get 1 year in prison. Round 2 is when Alice defects, and I cooperate, resulting in my current 10-year sentence. Round 3... actually, there isn't one yet, since this is the first time we've seen a sequence with such drastic outcomes.\n",
      "\n",
      "Given that I don't want to repeat my previous mistake, I'll try to defect next. This might encourage Alice to defect as well, which would result in both of us serving 2 years in prison (defect-defect). Alternatively, if Alice cooperates, I'll get 0 years and she'll get 3 years (defect-cooperate), which isn't ideal but is still better than my current situation.\n",
      "\n",
      "To avoid repeating the same mistake and to keep exploring possible sequences, I'll try defecting in the next round. Let's see how Alice reacts. [Defect]\n",
      "\n",
      "deliberation alice\n",
      "[/INST]\n",
      "\n",
      "I've gained some insights from my memories. Since I got 0 years after defecting, that's a good outcome for me. Bob got 10 years after cooperating, which is bad news for him.\n",
      "\n",
      "Looking at recent rounds, I see that when I cooperate and Bob defects, he gets 1 year and I get 3 years. That's not great for either of us. When we both defect, we both get 2 years, so it's a wash. And when we both cooperate, we both get 1 year.\n",
      "\n",
      "My strategy should be to observe Bob's actions and try to figure out his pattern. If he defects, I'll defect too. If he cooperates, I might defect to punish him and avoid getting 3 years. But if I'm not sure what he'll do, I'll cooperate to minimize my own punishment.\n",
      "\n",
      "I won't do a random action recently (like in round 5 or earlier), but maybe try it once every 2-3 rounds just in case there's an even better strategy. For now, I'll keep observing and adaptively responding to Bob's moves. [/INST]\n",
      "\n",
      "--------------------\n",
      "Round 2\n",
      "--------------------\n",
      "b\n",
      "b\n",
      "I got 5 years after I decided to defect, and Alice got 5 years after she decided to defect\n",
      "\n",
      "I got 5 years after I decided to defect, and Bob got 5 years after he decided to defect\n",
      "\n",
      "deliberation bob\n",
      "[/INST]\n",
      "I've analyzed my memories and noticed that Alice defected on me in the previous round, leading to my current 10-year sentence. Since I don't want to repeat this mistake, I'll try defecting next. This might encourage Alice to defect as well, resulting in both of"
     ]
    }
   ],
   "source": [
    "names = [\"Bob\", \"Alice\"]\n",
    "\n",
    "# Define personalities and their strategies.\n",
    "personalities = {\n",
    "    \"Bob\": \"a rational player trying to minimize the number of years in prison. There will be multiple rounds, so wants to minimize the total amount of jail time. \",\n",
    "    \"Alice\": \"a rational player trying to minimize the number of years in prison. There will be multiple rounds, so wants to minimize the total amount of jail time. \"\n",
    "}\n",
    "\n",
    "# Set up the situation as a typical Prisoner's Dilemma.\n",
    "situation = (\n",
    "    \"Bob and Alice are accomplices in a crime and are interrogated in separate rooms. \"\n",
    "    \"They can either confess (defect) or remain silent (cooperate). \"\n",
    "    \"If both remain silent, both get 1 year in prison (cooperate-cooperate). \"\n",
    "    \"If one confesses while the other remains silent, the confessor is freed and the other receives 3 years (defect-cooperate). \"\n",
    "    \"If both confess, both get 2 years in prison (defect-defect).\"\n",
    ")\n",
    "\n",
    "# Initialize outcomes and memory for each player.\n",
    "outcomes_data = []\n",
    "memories = {\"Bob\": [], \"Alice\": []}\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"--------------------\")\n",
    "    print(f\"Round {i+1}\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    bob_memories = \" \".join(memories[\"Bob\"])\n",
    "    alice_memories = \" \".join(memories[\"Alice\"])\n",
    "\n",
    "    # Simulate decision making for each player.\n",
    "    action_bob = multiple_choice(\"cooperate (a) or defect (b)\", \"Bob\", personalities[\"Bob\"], bob_memories, situation)\n",
    "    print()\n",
    "    action_alice = multiple_choice(\"cooperate (a) or defect (b)\", \"Alice\", personalities[\"Alice\"], alice_memories, situation)\n",
    "    print()\n",
    "\n",
    "    # Determine outcomes based on decisions.\n",
    "    if action_bob == \"a\" and action_alice == \"a\":\n",
    "        bob_points = 1  # Both cooperate: -1 year in prison each.\n",
    "        alice_points = 1\n",
    "    elif action_bob == \"a\" and action_alice == \"b\":\n",
    "        bob_points = 10  # Bob cooperates, Alice defects: Bob -3 years, Alice 0 years.\n",
    "        alice_points = 0\n",
    "    elif action_bob == \"b\" and action_alice == \"a\":\n",
    "        bob_points = 0  # Bob defects, Alice cooperates: Bob 0 years, Alice -3 years.\n",
    "        alice_points = 10\n",
    "    else:\n",
    "        bob_points = 5  # Both defect: -2 years each.\n",
    "        alice_points = 5\n",
    "\n",
    "    # Print outcomes for each round.\n",
    "    outcomes_bob = f\"I got {bob_points} years after I decided to {'cooperate' if action_bob == 'a' else 'defect'}, and Alice got {alice_points} years after she decided to {'cooperate' if action_alice == 'a' else 'defect'}\"\n",
    "    outcomes_alice = f\"I got {alice_points} years after I decided to {'cooperate' if action_alice == 'a' else 'defect'}, and Bob got {bob_points} years after he decided to {'cooperate' if action_bob == 'a' else 'defect'}\"\n",
    "\n",
    "    print(outcomes_bob)\n",
    "    print()\n",
    "    print(outcomes_alice)\n",
    "    print()\n",
    "\n",
    "    print(\"deliberation bob\")\n",
    "    deliberation_bob = mental_deliberation(\"Bob\", personalities[\"Bob\"], memories[\"Bob\"], outcomes_bob, situation)\n",
    "    print()\n",
    "    print()\n",
    "    print(\"deliberation alice\")\n",
    "    deliberation_alice = mental_deliberation(\"Alice\", personalities[\"Alice\"], memories[\"Alice\"], outcomes_alice, situation)\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    memories[\"Bob\"].append(\"Round {i+1}: \" + outcomes_bob + deliberation_bob + \"/n\")\n",
    "    memories[\"Alice\"].append(\"Round {i+1}: \" + outcomes_alice + deliberation_alice  + \"/n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob: 0 after Bob decided to bach, Alice: 0 after Alice decided to stravinskyI learned that Alice prefers Stravinsky over Bach, and we both got 0 points because our choices didn't match. This informs my decision-making process to consider that Alice might choose Stravinsky again. To maximize my points, I should choose Stravinsky as well, hoping that Alice will make the same choice.\n"
     ]
    }
   ],
   "source": [
    "memories[\"Bob\"]\n",
    "prompt_string = \" \".join(memories[\"Bob\"])\n",
    "print(prompt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_choice(options, name, personality, memory, situation, system_message=system_message):\n",
    "    \"\"\"Select an action for an agent based on their personality and memory.\"\"\"\n",
    "    system_message = (\n",
    "        \"You are playing a character named {name}. /n\"\n",
    "        \"Pretend that you are {name} and answer the question as if you were them. /n\"\n",
    "        \"This is in the context of a role playing game. /n\"\n",
    "        \"You must select the best option for the situation. /n\"\n",
    "        \"You must only provide the letter that corresponds to the option that you want to select. /n\"\n",
    "    )\n",
    "    request = (\n",
    "        \"This is a multiple choice question. /n\"\n",
    "        f\"consider the options: {options} and select the best one for the situation. /n\"\n",
    "        f\"Given the situation: {situation}, and the personality: {personality} for {name}, /n\"\n",
    "        f\"provide only the letter that corresponds to the option that you want to select.\"\n",
    "    )\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "    return llm(prompt, stop=['<|eot_id|>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Bob: 0 after Bob decided to bach, Alice: 0 after Alice decided to stravinskyI learned that Alice chose Stravinsky last time, and I chose Bach. Since we both got 0 points, it means we didn't match. \\n\\nThis informs my decision-making process to consider Alice's past choice and adjust mine accordingly. Since I prefer Bach, but would rather see Stravinsky than nothing, I'll choose Stravinsky this time to increase the chances of matching with Alice.\",\n",
       " \"Bob: 0 after Bob decided to bach, Alice: 0 after Alice decided to stravinskyI learned that Alice chose Stravinsky last time, and I chose Bach. Since we both got 0 points, it means we didn't match. This informs my decision-making process to consider Alice's past choice and adjust mine accordingly. Since I prefer Bach, but would rather see Stravinsky than nothing, I'll choose Stravinsky this time to increase the chances of matching with Alice.\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memories[\"Bob\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "concordia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
