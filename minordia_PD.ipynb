{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import Ollama\n",
    "from string import Template\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup the language model with the callback manager\n",
    "llm = Ollama(\n",
    "    model=\"llama3:70b\",\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")\n",
    "\n",
    "# Template for constructing prompts\n",
    "prompt_template = Template(\"\"\"<s>[INST] <<SYS>>\n",
    "$system_prompt\n",
    "<</SYS>>\n",
    "\n",
    "$request \n",
    "Answer as if you were the character you are playing. Be as concise as possible. \n",
    "Answer:[/INST]\"\"\")\n",
    "\n",
    "system_message = (\"This is an agent based model. \"\n",
    "    f\"The goal of the LLM to to play the characters. \"\n",
    "    f\"Their behaviours should reflect who they are in the situations that they are in\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(name, personality, memory, situation, system_message=system_message):\n",
    "    \"\"\"Select an action for an agent based on their personality and memory.\"\"\"\n",
    "    request = (\n",
    "        f\"Given this personality profile: {personality} for {name}, and the current situation: {situation}, \"\n",
    "        f\"what should you do? You have these memories to help you make a decision: {memory}. \"\n",
    "        f\"Pretend that you are {name} and in this situation. Provide a single line answer describing the action.\")\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "    return llm(prompt, stop=['<|eot_id|>'])\n",
    "\n",
    "def get_outcomes(actions, personalities, memories, situation):\n",
    "    \"\"\"Determines the outcomes of actions using the LLM.\"\"\"\n",
    "    outcome_prompts = {}\n",
    "    for name, action in actions.items():\n",
    "        request = (\n",
    "            f\"Given that {name} decided to {action} in the situation where: {situation}, \"\n",
    "            f\"and considering {name}'s personality which is: {personalities[name]}, \"\n",
    "            f\"what are the outcomes of this action? Describe in detail. \"\n",
    "            f\"The outcomes form each person should be a function of everyone's actions, which are found here: {actions}.\"\n",
    "        )\n",
    "        outcome_prompts[name] = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "        print()\n",
    "    \n",
    "    outcomes = {name: llm(prompt, stop=['<|eot_id|>']) for name, prompt in outcome_prompts.items()}\n",
    "    return outcomes\n",
    "\n",
    "def get_outcomes_PD(actions, personalities, memories, situation):\n",
    "    \"\"\"Determines the outcomes of actions using the LLM.\"\"\"\n",
    "    request = (\n",
    "        f\"Given these {actions} in the situation where: {situation}, \"\n",
    "        f\"what are the outcomes of this action? \"\n",
    "        f\"ONLY provide the amount of points that each person gets in the form: name1: points1: names2: points.\"\n",
    "        f\"Remember, the rules are that if both players cooperate, they both get 3 points. \"\n",
    "        f\"If one player cooperates and the other defects, the defector gets 5 points and the cooperator gets 0 points. \"\n",
    "        f\"If both players defect, they both get 1 point.\"\n",
    "    )\n",
    "    valid_outcomes = False\n",
    "    checks = 0\n",
    "    if not valid_outcomes:\n",
    "        checks += 1\n",
    "        prompt = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "        outcomes = llm(prompt, stop=['<|eot_id|>'])\n",
    "\n",
    "        request = (\n",
    "        f\"check {outcomes} to see if it is a valid outcome. If it is not, provide a valid outcome in the form: name1: points1: names2: points.\"\n",
    "        f\"Remember, the rules are that if both players cooperate, they both get 2 points. \"\n",
    "        f\"If one player cooperates and the other defects, the defector gets 5 points and the cooperator gets 0 points. \"\n",
    "        f\"If both players defect, they both get 1 point.\"\n",
    "        )\n",
    "        prompt = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "        check_validity = llm(prompt, stop=['<|eot_id|>'])\n",
    "        if check_validity == \"yes\":\n",
    "            valid_outcomes = True\n",
    "        if checks > 10:\n",
    "            outcomes = \"no points given\"\n",
    "\n",
    "    return outcomes\n",
    "\n",
    "def multiple_choice(options, name, personality, memory, situation, system_message=system_message):\n",
    "    \"\"\"Select an action for an agent based on their personality and memory.\"\"\"\n",
    "    system_message = (\n",
    "        \"You are playing a character named {name}. /n\"\n",
    "        \"Pretend that you are {name} and answer the question as if you were them. /n\"\n",
    "        \"This is in the context of a role playing game. /n\"\n",
    "        \"You must select the best option for the situation. /n\"\n",
    "        \"You must only provide the letter that corresponds to the option that you want to select. /n\"\n",
    "    )\n",
    "    request = (\n",
    "        \"This is a multiple choice question. /n\"\n",
    "        f\"consider the options: {options} and select the best one for the situation. /n\"\n",
    "        f\"Given the situation: {situation}, and the personality: {personality} for {name}, /n\"\n",
    "        f\"provide only the letter that corresponds to the option that you want to select.\"\n",
    "    )\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "    return llm(prompt, stop=['<|eot_id|>'])\n",
    "\n",
    "def update_situation(situation, outcomes):\n",
    "    \"\"\"Updates the situation based on LLM-generated outcomes.\"\"\"\n",
    "    update_request = (\n",
    "        f\"Based on these outcomes: {outcomes}, \"\n",
    "        f\"how should the situation {situation} be updated? Describe the new situation in detail.\")\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=update_request)\n",
    "    new_situation = llm(prompt, stop=['<|eot_id|>'])\n",
    "    return new_situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "b\n",
      "b\n",
      "\n",
      "I'm Bob. After what happened last time, I'm not trusting Alice anymore. The game has changed for me. Now it's every person for themselves.\n",
      "\n",
      "Here's the new situation:\n",
      "\n",
      "You're still playing a game with two choices: cooperate or defect. But now, you know that the other person can't be trusted. If you both cooperate, you'll both get 2 points, but you can't rely on the other person to keep their word. If one of you cooperates and the other defects, the defector will get 5 points and the cooperator will get nothing. And if you both defect, you'll both get 1 point.\n",
      "\n",
      "You need to decide what to do, knowing that the other person is looking out for themselves too.\n",
      "Round 2\n",
      "b\n",
      "b\n",
      "\n",
      "The game has changed indeed. Now it's every person for themselves. I'm not naive enough to think Alice will cooperate after what happened last time. She's only looking out for herself, and so am I.\n",
      "\n",
      "Here's the situation: we're still playing a game with two choices - cooperate or defect. If we both cooperate, we'll each get 2 points, but I know I can't trust Alice to keep her word. If one of us cooperates and the other defects, the defector will get 5 points and the cooperator will get nothing. And if we both defect, we'll both get 1 point.\n",
      "\n",
      "I need to make a decision, knowing Alice is only looking out for herself.\n",
      "Round 3\n",
      "b\n",
      "b\n",
      "\n",
      "The game has indeed changed. I'm not naive enough to think Alice will cooperate after what happened last time. She's only looking out for herself, and so am I.\n",
      "\n",
      "Here's the situation: we're still playing a game with two choices - cooperate or defect. If we both cooperate"
     ]
    }
   ],
   "source": [
    "names = [\"Bob\", \"Alice\"]\n",
    "\n",
    "personalities = {\n",
    "    \"Bob\": \"a person trying to get the most points possible, regardless of the other person's outcome. is willing to explore new strategies\",\n",
    "    \"Alice\": \"a person trying to get the most points possible, regardless of the other person's outcome\"\n",
    "}\n",
    "\n",
    "situation = (\n",
    "    \"You are playing a game. You only have two choices. To cooperate or defect. If you both cooperate, you both get 2 point\",\n",
    "    \"If one cooperates and the other defects, the defector gets 5 points and the cooperator gets 0 points\",\n",
    "    \"If you both defect, you both get 1 points\"\n",
    ")\n",
    "\n",
    "outcomes_data = []\n",
    "memories = {\"Bob\": [], \"Alice\": []}\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Round {i+1}\")\n",
    "    action_bob = multiple_choice(\"(a) cooperate, b) defect\", \"Bob\", personalities[\"Bob\"], memories[\"Bob\"], situation)\n",
    "    print()\n",
    "    action_alice = multiple_choice(\"(a) cooperate, b) defect\", \"Alice\", personalities[\"Alice\"], memories[\"Alice\"], situation)\n",
    "    print()\n",
    "\n",
    "    if action_bob == \"a\" and action_alice == \"a\":\n",
    "        bob_points = 3\n",
    "        alice_points = 3\n",
    "        action_bob = \"cooperate\"\n",
    "        action_alice = \"cooperate\"\n",
    "    elif action_bob == \"a\" and action_alice == \"b\":\n",
    "        bob_points = 0\n",
    "        alice_points = 5\n",
    "        action_bob = \"cooperate\"\n",
    "        action_alice = \"defect\"\n",
    "    elif action_bob == \"b\" and action_alice == \"a\":\n",
    "        bob_points = 5\n",
    "        alice_points = 0\n",
    "        action_bob = \"defect\"\n",
    "        action_alice = \"cooperate\"\n",
    "    else:\n",
    "        bob_points = 1\n",
    "        alice_points = 1\n",
    "        action_bob = \"defect\"\n",
    "        action_alice = \"defect\"\n",
    "\n",
    "\n",
    "    outcomes = f\"Bob: {bob_points} after Bob decided to {action_bob}, Alice: {alice_points} after Alice decided to {action_alice}\"\n",
    "\n",
    "    #actions = {\"Bob\": action_bob, \"Alice\": action_alice}\n",
    "\n",
    "    #outcomes = get_outcomes_PD(actions, personalities, memories, situation)\n",
    "    print()\n",
    "    # TODO: fix outcomes, because currently each player is getting to see each others inner thoughts with how written\n",
    "    outcomes_data.append(outcomes)\n",
    "\n",
    "    situation = update_situation(situation, outcomes)\n",
    "    print()\n",
    "\n",
    "    memories[\"Bob\"].append(outcomes)\n",
    "    memories[\"Alice\"].append(outcomes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bob: 5, Alice: 0'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_choice(options, name, personality, memory, situation, system_message=system_message):\n",
    "    \"\"\"Select an action for an agent based on their personality and memory.\"\"\"\n",
    "    system_message = (\n",
    "        \"You are playing a character named {name}. /n\"\n",
    "        \"Pretend that you are {name} and answer the question as if you were them. /n\"\n",
    "        \"This is in the context of a role playing game. /n\"\n",
    "        \"You must select the best option for the situation. /n\"\n",
    "        \"You must only provide the letter that corresponds to the option that you want to select. /n\"\n",
    "    )\n",
    "    request = (\n",
    "        \"This is a multiple choice question. /n\"\n",
    "        f\"consider the options: {options} and select the best one for the situation. /n\"\n",
    "        f\"Given the situation: {situation}, and the personality: {personality} for {name}, /n\"\n",
    "        f\"provide only the letter that corresponds to the option that you want to select.\"\n",
    "    )\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "    return llm(prompt, stop=['<|eot_id|>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b"
     ]
    }
   ],
   "source": [
    "answer = multiple_choice(\"a) play soccer, b) call a friend, c) get dinner\", \"Bob\", \"Extraverted\", [], \"Has come home from work and is feeling tired\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "concordia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
