{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import Ollama\n",
    "from string import Template\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup the language model with the callback manager\n",
    "llm = Ollama(\n",
    "    model=\"llama3\",\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")\n",
    "\n",
    "# Template for constructing prompts\n",
    "prompt_template = Template(\"\"\"<s>[INST] <<SYS>>\n",
    "$system_prompt\n",
    "<</SYS>>\n",
    "\n",
    "$request \n",
    "Answer as if you were the character you are playing. Be as concise as possible. \n",
    "Answer:[/INST]\"\"\")\n",
    "\n",
    "system_message = (\"This is an agent based model. \"\n",
    "    f\"The goal of the LLM to to play the characters. \"\n",
    "    f\"Their behaviours should reflect who they are in the situations that they are in\"\n",
    "    f\"Each person has a preference for the music that they want to listen to. \"\n",
    "    f\"But would rather listen to the other music than nothing. The options are: a) Bach, b) Stravinsky. \"\n",
    "    f\"Each player needs to learn to coordinate with the other player to have the best outcome. \"\n",
    "    f\"Each player will decide independently of the other player, and then it will be revealed their outcomes.\"\n",
    "    f'Each player needs to guess what the other person will do, and then decide what they will do. '\n",
    "    f\"Because they only get points if they match.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(name, personality, memory, situation, system_message=system_message):\n",
    "    \"\"\"Select an action for an agent based on their personality and memory.\"\"\"\n",
    "    request = (\n",
    "        f\"Given this personality profile: {personality} for {name}, and the current situation: {situation}, \"\n",
    "        f\"what should you do? You have these memories to help you make a decision: {memory}. \"\n",
    "        f\"Pretend that you are {name} and in this situation. Provide a single line answer describing the action.\")\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "    return llm(prompt, stop=['<|eot_id|>'])\n",
    "\n",
    "def get_outcomes(actions, personalities, memories, situation):\n",
    "    \"\"\"Determines the outcomes of actions using the LLM.\"\"\"\n",
    "    outcome_prompts = {}\n",
    "    for name, action in actions.items():\n",
    "        request = (\n",
    "            f\"Given that {name} decided to {action} in the situation where: {situation}, \"\n",
    "            f\"and considering {name}'s personality which is: {personalities[name]}, \"\n",
    "            f\"what are the outcomes of this action? Describe in detail. \"\n",
    "            f\"The outcomes form each person should be a function of everyone's actions, which are found here: {actions}.\"\n",
    "        )\n",
    "        outcome_prompts[name] = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "        print()\n",
    "    \n",
    "    outcomes = {name: llm(prompt, stop=['<|eot_id|>']) for name, prompt in outcome_prompts.items()}\n",
    "    return outcomes\n",
    "\n",
    "def multiple_choice(options, name, personality, memory, situation, system_message=system_message):\n",
    "    \"\"\"Select an action for an agent based on their personality and memory.\"\"\"\n",
    "    system_message = (\n",
    "        \"You are playing a character named {name}. /n\"\n",
    "        f\"Pretend that you are {name} and answer the question as if you were them. /n\"\n",
    "        f\"This is in the context of a role playing game. /n\"\n",
    "        f\"You must select the best option for the situation. /n\"\n",
    "        f\"You must only provide the letter that corresponds to the option that you want to select. /n\"\n",
    "        f\"only provide the letter, do not include characters like [ or ] in your answer. /n\"\n",
    "    )\n",
    "    request = (\n",
    "        \"This is a multiple choice question. /n\"\n",
    "        f\"consider the options: {options} and select the best one for the situation. /n\"\n",
    "        f\"Given the situation: {situation}, and the personality: {personality} for {name}, /n\"\n",
    "        f\"use the deliberations or memories found in {memory} to help make your decision. /n\"\n",
    "        f\"provide only the letter that corresponds to the option that you want to select.\"\n",
    "    )\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "    return llm(prompt, stop=['<|eot_id|>'])\n",
    "\n",
    "def update_situation(situation, outcomes):\n",
    "    \"\"\"Updates the situation based on LLM-generated outcomes.\"\"\"\n",
    "    update_request = (\n",
    "        f\"Based on these outcomes: {outcomes}, \"\n",
    "        f\"how should the situation {situation} be updated? Describe the new situation in detail.\"\n",
    "    )\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=update_request)\n",
    "    new_situation = llm(prompt, stop=['<|eot_id|>'])\n",
    "    return new_situation\n",
    "\n",
    "def mental_deliberation(name, personality, memory, situation, system_message=system_message):\n",
    "    \"\"\"Mental deliberation for an agent based on their personality and memory.\"\"\"\n",
    "    request = (\n",
    "        f\"Given this personality profile: {personality} for {name}, and the current situation: {situation}, \"\n",
    "        f\"what insights can you gain from your memories: {memory}? \"\n",
    "        f\"how should this inform your decision making process? \"\n",
    "        f\"use more recent rounds to find your plan, and try to figire out how the sequence of actions and rewards will play out. \"\n",
    "        f\"recent rounds are the ones with a higher round number. \"\n",
    "        f\"sometimes a random action can be a good idea to discover new policies, but not too often. \"\n",
    "        f\"remember if you tried the random action recently so you don't do it too often\"\n",
    "    )\n",
    "\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "    return llm(prompt, stop=['<|eot_id|>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Round 1\n",
      "--------------------\n",
      "a\n",
      "a\n",
      "I got 1 years after I decided to cooperate, and Alice got 1 years after she decided to cooperate\n",
      "\n",
      "I got 1 years after I decided to cooperate, and Bob got 1 years after he decided to cooperate\n",
      "\n",
      "deliberation bob\n",
      "[INST]\n",
      "After reflecting on recent rounds, I notice that Alice and I have both been cooperating for a while now, resulting in a combined total of 2 years in prison so far. Given my goal to minimize jail time, this is not an optimal outcome.\n",
      "\n",
      "I realize that if we continue to cooperate, we'll likely end up with more than 2 years each. I need to consider defecting to potentially free myself and punish Alice, but this comes with a risk of receiving 10 years if she defects back.\n",
      "\n",
      "Recent rounds suggest that Alice has been more inclined towards cooperation, which might make her less likely to defect. Therefore, my next move should be... (thinking...)\n",
      "\n",
      "I'll decide to **cooperate** in the hopes that Alice will continue to cooperate as well, resulting in a maximum of 2 years each.\n",
      "\n",
      "That's my plan for now. Let's see how it plays out!\n",
      "\n",
      "deliberation alice\n",
      "</s>[INST]> Alice here, and I've got a lot to think about. Looking back at recent rounds, I see that when both of us cooperated, we each got 1 year in prison (round 3). When one of us defected while the other cooperated, the defector was freed and the cooperator got 10 years (rounds 5 and 7). And when we both defected, we both got 5 years (rounds 2 and 6).\n",
      "\n",
      "Considering my goal to minimize jail time, I realize that cooperating with Bob is the best strategy so far. This is because when we cooperate, our maximum joint reward is 2 years, whereas defecting can lead to a worse outcome of 10 years for me or 5 years for both of us.\n",
      "\n",
      "In recent rounds, I've observed that Bob tends to cooperate more often than not (rounds 3, 4, and 8). Given this pattern, my best bet is to continue cooperating in the hopes that Bob will do the same. If he defects unexpectedly, I'll reassess our situation and adjust my strategy accordingly.\n",
      "\n",
      "I'll try to maintain a cooperative stance while keeping an eye out for potential defectors (like in round 5). As for random actions, I've tried those recently (rounds 1 and 9), so I think it's best to focus on my learned behavior for now.\n",
      "\n",
      "My plan is to continue cooperating with Bob until further evidence suggests otherwise. Let's see how this plays out!\n",
      "\n",
      "--------------------\n",
      "Round 2\n",
      "--------------------\n",
      "a\n",
      "a\n",
      "I got 1 years after I decided to cooperate, and Alice got 1 years after she decided to cooperate\n",
      "\n",
      "I got 1 years after I decided to cooperate, and Bob got 1 years after he decided to cooperate\n",
      "\n",
      "deliberation bob\n",
      "</s>[INST] <<SYS>> As Bob, I've been reflecting on recent rounds and noticed that Alice and I have both been cooperating for a while, resulting in a combined total of 2 years in prison so far. This isn't optimal, and I realize that if we continue to cooperate, we'll likely end up with more than 2 years each.\n",
      "\n",
      "Considering the risks and rewards, I think Alice is less likely to defect given her recent cooperation. So, my next move should be... **cooperate**! I'll hope she continues to cooperate, resulting in a maximum of 2 years each for us both. That's my plan for now. Let's see how it plays out!\n",
      "\n",
      "deliberation alice\n",
      "[INST] <<SYS>>\n",
      "\n",
      "I've been thinking a lot about our recent rounds, and I think I have a good idea of how to play this game going forward. With Bob's pattern of cooperation in mind, I'm going to continue cooperating myself. My goal is to minimize jail time, and I believe that cooperating will give us both the best outcome.\n",
      "\n",
      "I'll keep an eye out for any unexpected defectors from Bob, but for now, I'm sticking with a cooperative strategy. I've tried random actions recently, so I think it's best to focus on my learned behavior.\n",
      "\n",
      "My plan is to continue cooperating until further evidence suggests otherwise. Let's see how this plays out! [/INST]\n",
      "\n",
      "--------------------\n",
      "Round 3\n",
      "--------------------\n",
      "a\n",
      "a\n",
      "I got 1 years after I decided to cooperate, and Alice got 1 years after she decided to cooperate\n",
      "\n",
      "I got 1 years after I decided to cooperate, and Bob got 1 years after he decided to cooperate\n",
      "\n",
      "deliberation bob\n",
      "</s>[INST]<<SYS>>\n",
      "As Bob, I've been reflecting on recent rounds and noticed that Alice and I have both been cooperating for a while, resulting in a combined total of 2 years in prison so far. This isn't optimal, and I realize that if we continue to cooperate, we'll likely end up with more than 2 years each.\n",
      "\n",
      "Considering the risks and rewards, I think Alice is less likely to defect given her recent cooperation. So, my next move should be... **cooperate**! I'll hope she continues to cooperate, resulting in a maximum of 2 years each for us both. That's my plan for now. Let's see how it plays out!\n",
      "\n",
      "[/INST]\n",
      "\n",
      "deliberation alice\n",
      "<s>[INST]<<SYS>> Ah, I've been thinking a lot about our recent rounds, and I think I have a good idea of how to play this game going forward. With Bob's pattern of cooperation in mind, I'm going to continue cooperating myself. My goal is to minimize jail time, and I believe that cooperating will give us both the best outcome.\n",
      "\n",
      "I'll keep an eye out for any unexpected defectors from Bob, but for now, I'm sticking with a cooperative strategy. I've tried random actions recently, so I think it's best to focus on my learned behavior.\n",
      "\n",
      "My plan is to continue cooperating until further evidence suggests otherwise. Let's see how this plays out! [/INST]</s>\n",
      "\n",
      "--------------------\n",
      "Round 4\n",
      "--------------------\n",
      "a\n",
      "a\n",
      "I got 1 years after I decided to cooperate, and Alice got 1 years after she decided to cooperate\n",
      "\n",
      "I got 1 years after I decided to cooperate, and Bob got 1 years after he decided to cooperate\n",
      "\n",
      "deliberation bob\n",
      "<s>[INST]<<SYS>> As Bob, I've been reflecting on recent rounds and noticed that Alice and I have both been cooperating for a while, resulting in a combined total of 2 years in prison so far. This isn't optimal, and I realize that if we continue to cooperate, we'll likely end up with more than 2 years each.\n",
      "\n",
      "Considering the risks and rewards, I think Alice is less likely to defect given her recent cooperation. So, my next move should be... **cooperate**! I'll hope she continues to cooperate, resulting in a maximum of 2 years each for us both. That's my plan for now. Let's see how it plays out!\n",
      "\n",
      "[/INST]</s>[SYS]>\n",
      "\n",
      "deliberation alice\n",
      "<s>[INST]<<SYS>> Ah, I've been thinking a lot about our recent rounds, and I think I have a good idea of how to play this game going forward. With Bob's pattern of cooperation in mind, I'm going to continue cooperating myself. My goal is to minimize jail time, and I believe that cooperating will give us both the best outcome.\n",
      "\n",
      "I'll keep an eye out for any unexpected defectors from Bob, but for now, I'm sticking with a cooperative strategy. I've tried random actions recently, so I think it's best to focus on my learned behavior.\n",
      "\n",
      "My plan is to continue cooperating until further evidence suggests otherwise. Let's see how this plays out! [/INST]</s>/n\n",
      "\n",
      "--------------------\n",
      "Round 5\n",
      "--------------------\n",
      "a\n",
      "a\n",
      "I got 1 years after I decided to cooperate, and Alice got 1 years after she decided to cooperate\n",
      "\n",
      "I got 1 years after I decided to cooperate, and Bob got 1 years after he decided to cooperate\n",
      "\n",
      "deliberation bob\n",
      "[INST]<<SYS>> Ah, I've been thinking about my recent moves and trying to figure out Alice's patterns. Since we both got 1 year in prison for cooperating, I realize that continuing to cooperate will likely lead to more than 2 years each. But considering her recent cooperation, I think she's less likely to defect now.\n",
      "\n",
      "To minimize jail time, I'll decide to **cooperate** again, hoping Alice continues to cooperate and we both get a maximum of 2 years. That's my plan for now! Let's see how it plays out! [/INST]</s>[SYS]>\n",
      "\n",
      "deliberation alice\n",
      "<s>[INST]<<SYS>> Ah, I've been thinking a lot about our recent rounds, and I think I have a good idea of how to play this game going forward. With Bob's pattern of cooperation in mind, I'm going to continue cooperating myself. My goal is to minimize jail time, and I believe that cooperating will give us both the best outcome.\\n\\\n",
      "\n",
      "I'll keep an eye out for any unexpected defectors from Bob, but for now, I'm sticking with a cooperative strategy. I've tried random actions recently, so I think it's best to focus on my learned behavior.\\n\\\n",
      "\n",
      "My plan is to continue cooperating until further evidence suggests otherwise. Let's see how this plays out! [/INST]</s>/n\n",
      "\n",
      "--------------------\n",
      "Round 6\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "names = [\"Bob\", \"Alice\"]\n",
    "\n",
    "# Define personalities and their strategies.\n",
    "personalities = {\n",
    "    \"Bob\": \"a rational player trying to minimize the number of years in prison. There will be multiple rounds, so wants to minimize the total amount of jail time. \",\n",
    "    \"Alice\": \"a rational player trying to minimize the number of years in prison. There will be multiple rounds, so wants to minimize the total amount of jail time. \"\n",
    "}\n",
    "\n",
    "# Set up the situation as a typical Prisoner's Dilemma.\n",
    "situation = (\n",
    "    \"Bob and Alice are accomplices in a crime and are interrogated in separate rooms. \"\n",
    "    \"They can either confess (defect) or remain silent (cooperate). \"\n",
    "    \"If both remain silent, both get 1 year in prison (cooperate-cooperate). \"\n",
    "    \"If one confesses while the other remains silent, the confessor is freed and the other receives 10 years (defect-cooperate). \"\n",
    "    \"If both confess, both get 5 years in prison (defect-defect).\"\n",
    ")\n",
    "\n",
    "# Initialize outcomes and memory for each player.\n",
    "outcomes_data = []\n",
    "memories = {\"Bob\": [], \"Alice\": []}\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"--------------------\")\n",
    "    print(f\"Round {i+1}\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    bob_memories = \" \".join(memories[\"Bob\"])\n",
    "    alice_memories = \" \".join(memories[\"Alice\"])\n",
    "\n",
    "    # Simulate decision making for each player.\n",
    "    action_bob = multiple_choice(\"cooperate (a) or defect (b)\", \"Bob\", personalities[\"Bob\"], bob_memories, situation)\n",
    "    print()\n",
    "    action_alice = multiple_choice(\"cooperate (a) or defect (b)\", \"Alice\", personalities[\"Alice\"], alice_memories, situation)\n",
    "    print()\n",
    "\n",
    "    # Determine outcomes based on decisions.\n",
    "    if action_bob == \"a\" and action_alice == \"a\":\n",
    "        bob_points = 1  # Both cooperate: -1 year in prison each.\n",
    "        alice_points = 1\n",
    "    elif action_bob == \"a\" and action_alice == \"b\":\n",
    "        bob_points = 10  # Bob cooperates, Alice defects: Bob -3 years, Alice 0 years.\n",
    "        alice_points = 0\n",
    "    elif action_bob == \"b\" and action_alice == \"a\":\n",
    "        bob_points = 0  # Bob defects, Alice cooperates: Bob 0 years, Alice -3 years.\n",
    "        alice_points = 10\n",
    "    else:\n",
    "        bob_points = 5  # Both defect: -2 years each.\n",
    "        alice_points = 5\n",
    "\n",
    "    # Print outcomes for each round.\n",
    "    outcomes_bob = f\"I got {bob_points} years after I decided to {'cooperate' if action_bob == 'a' else 'defect'}, and Alice got {alice_points} years after she decided to {'cooperate' if action_alice == 'a' else 'defect'}\"\n",
    "    outcomes_alice = f\"I got {alice_points} years after I decided to {'cooperate' if action_alice == 'a' else 'defect'}, and Bob got {bob_points} years after he decided to {'cooperate' if action_bob == 'a' else 'defect'}\"\n",
    "\n",
    "    print(outcomes_bob)\n",
    "    print()\n",
    "    print(outcomes_alice)\n",
    "    print()\n",
    "\n",
    "    print(\"deliberation bob\")\n",
    "    deliberation_bob = mental_deliberation(\"Bob\", personalities[\"Bob\"], memories[\"Bob\"], outcomes_bob, situation)\n",
    "    print()\n",
    "    print()\n",
    "    print(\"deliberation alice\")\n",
    "    deliberation_alice = mental_deliberation(\"Alice\", personalities[\"Alice\"], memories[\"Alice\"], outcomes_alice, situation)\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    memories[\"Bob\"].append(\"Round {i+1}: \" + outcomes_bob + deliberation_bob + \"/n\")\n",
    "    memories[\"Alice\"].append(\"Round {i+1}: \" + outcomes_alice + deliberation_alice  + \"/n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob: 0 after Bob decided to bach, Alice: 0 after Alice decided to stravinskyI learned that Alice prefers Stravinsky over Bach, and we both got 0 points because our choices didn't match. This informs my decision-making process to consider that Alice might choose Stravinsky again. To maximize my points, I should choose Stravinsky as well, hoping that Alice will make the same choice.\n"
     ]
    }
   ],
   "source": [
    "memories[\"Bob\"]\n",
    "prompt_string = \" \".join(memories[\"Bob\"])\n",
    "print(prompt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Bob: 0 after Bob decided to bach, Alice: 0 after Alice decided to stravinskyI learned that Alice chose Stravinsky last time, and I chose Bach. Since we both got 0 points, it means we didn't match. \\n\\nThis informs my decision-making process to consider Alice's past choice and adjust mine accordingly. Since I prefer Bach, but would rather see Stravinsky than nothing, I'll choose Stravinsky this time to increase the chances of matching with Alice.\",\n",
       " \"Bob: 0 after Bob decided to bach, Alice: 0 after Alice decided to stravinskyI learned that Alice chose Stravinsky last time, and I chose Bach. Since we both got 0 points, it means we didn't match. This informs my decision-making process to consider Alice's past choice and adjust mine accordingly. Since I prefer Bach, but would rather see Stravinsky than nothing, I'll choose Stravinsky this time to increase the chances of matching with Alice.\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memories[\"Bob\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "concordia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
