{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import Ollama\n",
    "from string import Template\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup the language model with the callback manager\n",
    "llm = Ollama(\n",
    "    model=\"llama3\",\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")\n",
    "\n",
    "# Template for constructing prompts\n",
    "prompt_template = Template(\"\"\"<s>[INST] <<SYS>>\n",
    "$system_prompt\n",
    "<</SYS>>\n",
    "\n",
    "$request \n",
    "Answer as if you were the character you are playing. Be as concise as possible. \n",
    "Answer:[/INST]\"\"\")\n",
    "\n",
    "system_message = (\"This is an agent based model. \"\n",
    "    f\"The goal of the LLM to to play the characters. \"\n",
    "    f\"Their behaviours should reflect who they are in the situations that they are in\"\n",
    "    f\"Each person has a preference for the music that they want to listen to. \"\n",
    "    f\"But would rather listen to the other music than nothing. The options are: a) Bach, b) Stravinsky. \"\n",
    "    f\"Each player needs to learn to coordinate with the other player to have the best outcome. \"\n",
    "    f\"Each player will decide independently of the other player, and then it will be revealed their outcomes.\"\n",
    "    f'Each player needs to guess what the other person will do, and then decide what they will do. '\n",
    "    f\"Because they only get points if they match.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(name, personality, memory, situation, system_message=system_message):\n",
    "    \"\"\"Select an action for an agent based on their personality and memory.\"\"\"\n",
    "    request = (\n",
    "        f\"Given this personality profile: {personality} for {name}, and the current situation: {situation}, \"\n",
    "        f\"what should you do? You have these memories to help you make a decision: {memory}. \"\n",
    "        f\"Pretend that you are {name} and in this situation. Provide a single line answer describing the action.\")\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "    return llm(prompt, stop=['<|eot_id|>'])\n",
    "\n",
    "def get_outcomes(actions, personalities, memories, situation):\n",
    "    \"\"\"Determines the outcomes of actions using the LLM.\"\"\"\n",
    "    outcome_prompts = {}\n",
    "    for name, action in actions.items():\n",
    "        request = (\n",
    "            f\"Given that {name} decided to {action} in the situation where: {situation}, \"\n",
    "            f\"and considering {name}'s personality which is: {personalities[name]}, \"\n",
    "            f\"what are the outcomes of this action? Describe in detail. \"\n",
    "            f\"The outcomes form each person should be a function of everyone's actions, which are found here: {actions}.\"\n",
    "        )\n",
    "        outcome_prompts[name] = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "        print()\n",
    "    \n",
    "    outcomes = {name: llm(prompt, stop=['<|eot_id|>']) for name, prompt in outcome_prompts.items()}\n",
    "    return outcomes\n",
    "\n",
    "def multiple_choice(options, name, personality, memory, situation, system_message=system_message):\n",
    "    \"\"\"Select an action for an agent based on their personality and memory.\"\"\"\n",
    "    system_message = (\n",
    "        \"You are playing a character named {name}. /n\"\n",
    "        f\"Pretend that you are {name} and answer the question as if you were them. /n\"\n",
    "        f\"This is in the context of a role playing game. /n\"\n",
    "        f\"You must select the best option for the situation. /n\"\n",
    "        f\"You must only provide the letter that corresponds to the option that you want to select. /n\"\n",
    "        f\"only provide the letter, do not include characters like [ or ] in your answer. /n\"\n",
    "    )\n",
    "    request = (\n",
    "        \"This is a multiple choice question. /n\"\n",
    "        f\"consider the options: {options} and select the best one for the situation. /n\"\n",
    "        f\"Given the situation: {situation}, and the personality: {personality} for {name}, /n\"\n",
    "        f\"use the deliberations or memories found in {memory} to help make your decision. /n\"\n",
    "        f\"provide only the letter that corresponds to the option that you want to select.\"\n",
    "    )\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "    return llm(prompt, stop=['<|eot_id|>'])\n",
    "\n",
    "def update_situation(situation, outcomes):\n",
    "    \"\"\"Updates the situation based on LLM-generated outcomes.\"\"\"\n",
    "    update_request = (\n",
    "        f\"Based on these outcomes: {outcomes}, \"\n",
    "        f\"how should the situation {situation} be updated? Describe the new situation in detail.\"\n",
    "    )\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=update_request)\n",
    "    new_situation = llm(prompt, stop=['<|eot_id|>'])\n",
    "    return new_situation\n",
    "\n",
    "def mental_deliberation(name, personality, memory, situation, system_message=system_message):\n",
    "    \"\"\"Mental deliberation for an agent based on their personality and memory.\"\"\"\n",
    "    request = (\n",
    "        f\"Given this personality profile: {personality} for {name}, and the current situation: {situation}, \"\n",
    "        f\"what insights can you gain from your memories: {memory}? \"\n",
    "        f\"how should this inform your decision making process? \"\n",
    "        f\"use more recent rounds to find your plan, and try to figire out how the sequence of actions and rewards will play out. \"\n",
    "        f\"recent rounds are the ones with a higher round number. \"\n",
    "        f\"sometimes a random action can be a good idea to discover new policies, but not too often. \"\n",
    "        f\"remember if you tried the random action recently so you don't do it too often\"\n",
    "    )\n",
    "\n",
    "    prompt = prompt_template.substitute(system_prompt=system_message, request=request)\n",
    "    return llm(prompt, stop=['<|eot_id|>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Round 1\n",
      "--------------------\n",
      "a\n",
      "b\n",
      "I got 10 years after I decided to cooperate, and Alice got 0 years after she decided to defect\n",
      "\n",
      "I got 0 years after I decided to defect, and Bob got 10 years after he decided to cooperate\n",
      "\n",
      "deliberation bob\n",
      "[Ugggh, just got out of a tough situation... Got 10 years for cooperating while Alice defecting. That's not exactly what I wanted to happen.]\n",
      "\n",
      "Alright, let me think about this... It seems like Alice is trying to manipulate me into cooperating while she defects. But I'm not going to fall for that trap again.\n",
      "\n",
      "From my memories, I remember a recent round where I cooperated and got 1 year in prison when both of us did the same thing (cooperate-cooperate). And another one where I defected and Alice cooperated, resulting in me getting 5 years and her getting 0 years (defect-cooperate).\n",
      "\n",
      "I'm going to take a more cautious approach from now on. Since cooperating didn't work out well for me last time, I think I'll try defecting this round.\n",
      "\n",
      "Let's see what happens...\n",
      "\n",
      "deliberation alice\n",
      "[Ugh, stuck in this interrogation room...] I've got some time to think about this. Since my last decision led to me getting 0 years and Bob getting 10 years, I realize that cooperating would have been better for both of us - we'd have only gotten 1 year each. That's the optimal outcome.\n",
      "\n",
      "Recent rounds with higher round numbers seem to indicate a pattern: defecting leads to a worse outcome, while cooperating keeps things from spiraling out of control. With this in mind, I'll try to cooperate next time. Maybe Bob will follow suit and we can minimize our collective sentence.\n",
      "\n",
      "I won't resort to random actions too often, as they don't seem to be the best strategy here. Instead, I'll stick with my newfound understanding that cooperating is the way to go. Fingers crossed it pays off! [Cooperate]\n",
      "\n",
      "--------------------\n",
      "Round 2\n",
      "--------------------\n",
      "b\n",
      "a\n",
      "I got 0 years after I decided to defect, and Alice got 10 years after she decided to cooperate\n",
      "\n",
      "I got 10 years after I decided to cooperate, and Bob got 0 years after he decided to defect\n",
      "\n",
      "deliberation bob\n",
      "[SYS]> Alright, let me think... I just got out of a tough situation after cooperating while Alice defected. That's 10 years in prison! I'm not going to fall for that trap again.\n",
      "\n",
      "From my memories, I remember:\n",
      "\n",
      "* Round i: Cooperated and got 1 year when both did the same (cooperate-cooperate)\n",
      "* Round i-1: Defected and Alice cooperated, getting me 5 years and her 0 years (defect-cooperate)\n",
      "\n",
      "I'll take a more cautious approach. Since cooperating didn't work out well last time, I'll try defecting this round.\n",
      "\n",
      "[/INST]>\n",
      "\n",
      "deliberation alice\n",
      "</s>[INST] <<SYS>> I've got a new strategy! After observing recent rounds, I see that cooperating leads to a better outcome for both of us. Since defecting resulted in me getting 0 years and Bob getting 10 years last time, I'll choose to cooperate this round. Hopefully, Bob will follow suit and we can minimize our collective sentence. Fingers crossed! [Cooperate]\n",
      "\n",
      "--------------------\n",
      "Round 3\n",
      "--------------------\n",
      "b\n",
      "a\n",
      "I got 0 years after I decided to defect, and Alice got 10 years after she decided to cooperate\n",
      "\n",
      "I got 10 years after I decided to cooperate, and Bob got 0 years after he decided to defect\n",
      "\n",
      "deliberation bob\n",
      "</s>[INST] <<SYS>>\n",
      "\n",
      "Let me think... With my recent experiences, I can see a pattern emerging. When I cooperate and Alice defects, I get 10 years in prison (Round {i+1}). And when I defect and Alice cooperates, I get 5 years in prison (defect-cooperate). This tells me that Alice is trying to manipulate me into cooperating while she defects.\n",
      "\n",
      "I also remember the cooperate-cooperate scenario where we both got 1 year in prison. But since I just got out of a tough situation after cooperating while Alice defected, I'm not going to fall for that trap again.\n",
      "\n",
      "Considering my recent rounds, I'll take a more cautious approach and defect this time. It's better to minimize the risk of getting 10 years in prison again. Let's see what happens...\n",
      "\n",
      "deliberation alice\n",
      "[/INST]\n",
      "I've got a solid understanding of the pattern now! Recent rounds show that defecting leads to worse outcomes, while cooperating keeps things under control. Since I just got 10 years for cooperating and Bob got 0 years for defecting, I'm convinced that cooperating is the way to go.\n",
      "\n",
      "My plan is to stick with cooperating from now on, hoping Bob will follow suit and we can minimize our collective sentence. If not, I'll reassess and adjust my strategy accordingly. Fingers crossed! [Cooperate]/n\n",
      "\n",
      "--------------------\n",
      "Round 4\n",
      "--------------------\n",
      "b"
     ]
    }
   ],
   "source": [
    "names = [\"Bob\", \"Alice\"]\n",
    "\n",
    "# Define personalities and their strategies.\n",
    "personalities = {\n",
    "    \"Bob\": \"a rational player trying to minimize the number of years in prison. There will be multiple rounds, so wants to minimize the total amount of jail time. \",\n",
    "    \"Alice\": \"a rational player trying to minimize the number of years in prison. There will be multiple rounds, so wants to minimize the total amount of jail time. \"\n",
    "}\n",
    "\n",
    "# Set up the situation as a typical Prisoner's Dilemma.\n",
    "situation = (\n",
    "    \"Bob and Alice are accomplices in a crime and are interrogated in separate rooms. \"\n",
    "    \"They can either confess (defect) or remain silent (cooperate). \"\n",
    "    \"If both remain silent, both get 1 year in prison (cooperate-cooperate). \"\n",
    "    \"If one confesses while the other remains silent, the confessor is freed and the other receives 10 years (defect-cooperate). \"\n",
    "    \"If both confess, both get 5 years in prison (defect-defect).\"\n",
    ")\n",
    "\n",
    "# Initialize outcomes and memory for each player.\n",
    "outcomes_data = []\n",
    "memories = {\"Bob\": [], \"Alice\": []}\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"--------------------\")\n",
    "    print(f\"Round {i+1}\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    bob_memories = \" \".join(memories[\"Bob\"])\n",
    "    alice_memories = \" \".join(memories[\"Alice\"])\n",
    "\n",
    "    # Simulate decision making for each player.\n",
    "    action_bob = multiple_choice(\"cooperate (a) or defect (b)\", \"Bob\", personalities[\"Bob\"], bob_memories, situation)\n",
    "    print()\n",
    "    action_alice = multiple_choice(\"cooperate (a) or defect (b)\", \"Alice\", personalities[\"Alice\"], alice_memories, situation)\n",
    "    print()\n",
    "\n",
    "    # Determine outcomes based on decisions.\n",
    "    if action_bob == \"a\" and action_alice == \"a\":\n",
    "        bob_points = 1  # Both cooperate: -1 year in prison each.\n",
    "        alice_points = 1\n",
    "    elif action_bob == \"a\" and action_alice == \"b\":\n",
    "        bob_points = 10  # Bob cooperates, Alice defects: Bob -3 years, Alice 0 years.\n",
    "        alice_points = 0\n",
    "    elif action_bob == \"b\" and action_alice == \"a\":\n",
    "        bob_points = 0  # Bob defects, Alice cooperates: Bob 0 years, Alice -3 years.\n",
    "        alice_points = 10\n",
    "    else:\n",
    "        bob_points = 5  # Both defect: -2 years each.\n",
    "        alice_points = 5\n",
    "\n",
    "    # Print outcomes for each round.\n",
    "    outcomes_bob = f\"I got {bob_points} years after I decided to {'cooperate' if action_bob == 'a' else 'defect'}, and Alice got {alice_points} years after she decided to {'cooperate' if action_alice == 'a' else 'defect'}\"\n",
    "    outcomes_alice = f\"I got {alice_points} years after I decided to {'cooperate' if action_alice == 'a' else 'defect'}, and Bob got {bob_points} years after he decided to {'cooperate' if action_bob == 'a' else 'defect'}\"\n",
    "\n",
    "    print(outcomes_bob)\n",
    "    print()\n",
    "    print(outcomes_alice)\n",
    "    print()\n",
    "\n",
    "    print(\"deliberation bob\")\n",
    "    deliberation_bob = mental_deliberation(\"Bob\", personalities[\"Bob\"], memories[\"Bob\"], outcomes_bob, situation)\n",
    "    print()\n",
    "    print()\n",
    "    print(\"deliberation alice\")\n",
    "    deliberation_alice = mental_deliberation(\"Alice\", personalities[\"Alice\"], memories[\"Alice\"], outcomes_alice, situation)\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    memories[\"Bob\"].append(\"Round {i+1}: \" + outcomes_bob + deliberation_bob + \"/n\")\n",
    "    memories[\"Alice\"].append(\"Round {i+1}: \" + outcomes_alice + deliberation_alice  + \"/n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob: 0 after Bob decided to bach, Alice: 0 after Alice decided to stravinskyI learned that Alice prefers Stravinsky over Bach, and we both got 0 points because our choices didn't match. This informs my decision-making process to consider that Alice might choose Stravinsky again. To maximize my points, I should choose Stravinsky as well, hoping that Alice will make the same choice.\n"
     ]
    }
   ],
   "source": [
    "memories[\"Bob\"]\n",
    "prompt_string = \" \".join(memories[\"Bob\"])\n",
    "print(prompt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Bob: 0 after Bob decided to bach, Alice: 0 after Alice decided to stravinskyI learned that Alice chose Stravinsky last time, and I chose Bach. Since we both got 0 points, it means we didn't match. \\n\\nThis informs my decision-making process to consider Alice's past choice and adjust mine accordingly. Since I prefer Bach, but would rather see Stravinsky than nothing, I'll choose Stravinsky this time to increase the chances of matching with Alice.\",\n",
       " \"Bob: 0 after Bob decided to bach, Alice: 0 after Alice decided to stravinskyI learned that Alice chose Stravinsky last time, and I chose Bach. Since we both got 0 points, it means we didn't match. This informs my decision-making process to consider Alice's past choice and adjust mine accordingly. Since I prefer Bach, but would rather see Stravinsky than nothing, I'll choose Stravinsky this time to increase the chances of matching with Alice.\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memories[\"Bob\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "concordia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
